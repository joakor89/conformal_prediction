{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c20c53-dea4-4bfa-a423-2644581011c9",
   "metadata": {},
   "source": [
    "# Multi-Class Conformal Prediction\n",
    "\n",
    "### Getting Ext Repositories & Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accc9c3a-b612-4321-b668-d4543c9e2e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: venn-abers in /opt/anaconda3/lib/python3.12/site-packages (1.4.6)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from venn-abers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from venn-abers) (1.5.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from venn-abers) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->venn-abers) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->venn-abers) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->venn-abers) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->venn-abers) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->venn-abers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->venn-abers) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->venn-abers) (1.16.0)\n",
      "Requirement already satisfied: catboost in /opt/anaconda3/lib/python3.12/site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from plotly->catboost) (8.2.3)\n",
      "Requirement already satisfied: dtype_diet in /opt/anaconda3/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from dtype_diet) (2.2.2)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/lib/python3.12/site-packages (from dtype_diet) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.0->dtype_diet) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.0->dtype_diet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.0->dtype_diet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.0->dtype_diet) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->dtype_diet) (1.16.0)\n",
      "Requirement already satisfied: openml in /opt/anaconda3/lib/python3.12/site-packages (0.15.1)\n",
      "Requirement already satisfied: liac-arff>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openml) (2.5.0)\n",
      "Requirement already satisfied: xmltodict in /opt/anaconda3/lib/python3.12/site-packages (from openml) (0.14.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from openml) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/anaconda3/lib/python3.12/site-packages (from openml) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.12/site-packages (from openml) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from openml) (2.2.2)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from openml) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from openml) (1.26.4)\n",
      "Requirement already satisfied: minio in /opt/anaconda3/lib/python3.12/site-packages (from openml) (7.2.15)\n",
      "Requirement already satisfied: pyarrow in /opt/anaconda3/lib/python3.12/site-packages (from openml) (16.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from openml) (4.66.5)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from openml) (24.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.0->openml) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.0.0->openml) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil->openml) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=0.18->openml) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=0.18->openml) (3.5.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from minio->openml) (2025.1.31)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.12/site-packages (from minio->openml) (2.2.3)\n",
      "Requirement already satisfied: argon2-cffi in /opt/anaconda3/lib/python3.12/site-packages (from minio->openml) (21.3.0)\n",
      "Requirement already satisfied: pycryptodome in /opt/anaconda3/lib/python3.12/site-packages (from minio->openml) (3.22.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.12/site-packages (from minio->openml) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->openml) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->openml) (3.7)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/anaconda3/lib/python3.12/site-packages (from argon2-cffi->minio->openml) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade venn-abers\n",
    "\n",
    "!pip install catboost\n",
    "!pip install dtype_diet\n",
    "\n",
    "#install OpenML\n",
    "!pip install openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ca4cf87-a7df-43dc-a46b-fcb4d8c0c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Path & Fetching\n",
    "import openml\n",
    "\n",
    "# Date & Time\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "# Notebook Optimizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# OS\n",
    "from dtype_diet import report_on_dataframe, optimize_dtypes\n",
    "\n",
    "# GC\n",
    "import gc\n",
    "\n",
    "#Scikit-Learn\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import CalibrationDisplay, calibration_curve\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score\n",
    "from sklearn.metrics import average_precision_score, recall_score, f1_score, roc_auc_score, log_loss, brier_score_loss\n",
    "\n",
    "\n",
    "# Categorical Boosting (CatBoost)\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Light Gradient Boosting \n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# VennAbers\n",
    "from venn_abers import VennAbersCalibrator\n",
    "\n",
    "# SciPy\n",
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0687226-ee9c-441d-832b-157a37eb780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab Render\n",
    "pio.renderers.default = 'colab'\n",
    "\n",
    "# Seabor styling Set-Up\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pandas Set-Up\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57900d93-471e-413a-996c-1c24144b7bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        </script>\n",
       "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.0.1.min\"</script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adab5be8-ac38-4338-99d5-6cfcb15f497f",
   "metadata": {},
   "source": [
    "#### Checking CUDA GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90e1899-f109-462e-a21e-8b7572e95394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU support) is available: False\n"
     ]
    }
   ],
   "source": [
    "is_cuda_available = torch.cuda.is_available()\n",
    "\n",
    "print(f\"CUDA (GPU support) is available: {is_cuda_available}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b043e1e-5e4f-44f1-916f-7f377702b096",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e7a2495-0185-4d12-9602-41eaeb905563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    did             name  version uploader  status format  MajorityClassSize  \\\n",
      "2     2           anneal        1        1  active   ARFF              684.0   \n",
      "3     3         kr-vs-kp        1        1  active   ARFF             1669.0   \n",
      "4     4            labor        1        1  active   ARFF               37.0   \n",
      "5     5       arrhythmia        1        1  active   ARFF              245.0   \n",
      "6     6           letter        1        1  active   ARFF              813.0   \n",
      "7     7        audiology        1        1  active   ARFF               57.0   \n",
      "8     8  liver-disorders        1        1  active   ARFF                NaN   \n",
      "9     9            autos        1        1  active   ARFF               67.0   \n",
      "10   10            lymph        1        1  active   ARFF               81.0   \n",
      "11   11    balance-scale        1        1  active   ARFF              288.0   \n",
      "\n",
      "    MaxNominalAttDistinctValues  MinorityClassSize  NumberOfClasses  \\\n",
      "2                           7.0                8.0              5.0   \n",
      "3                           3.0             1527.0              2.0   \n",
      "4                           3.0               20.0              2.0   \n",
      "5                          13.0                2.0             13.0   \n",
      "6                          26.0              734.0             26.0   \n",
      "7                          24.0                1.0             24.0   \n",
      "8                           NaN                NaN              0.0   \n",
      "9                          22.0                3.0              6.0   \n",
      "10                          8.0                2.0              4.0   \n",
      "11                          3.0               49.0              3.0   \n",
      "\n",
      "    NumberOfFeatures  NumberOfInstances  NumberOfInstancesWithMissingValues  \\\n",
      "2               39.0              898.0                               898.0   \n",
      "3               37.0             3196.0                                 0.0   \n",
      "4               17.0               57.0                                56.0   \n",
      "5              280.0              452.0                               384.0   \n",
      "6               17.0            20000.0                                 0.0   \n",
      "7               70.0              226.0                               222.0   \n",
      "8                6.0              345.0                                 0.0   \n",
      "9               26.0              205.0                                46.0   \n",
      "10              19.0              148.0                                 0.0   \n",
      "11               5.0              625.0                                 0.0   \n",
      "\n",
      "    NumberOfMissingValues  NumberOfNumericFeatures  NumberOfSymbolicFeatures  \n",
      "2                 22175.0                      6.0                      33.0  \n",
      "3                     0.0                      0.0                      37.0  \n",
      "4                   326.0                      8.0                       9.0  \n",
      "5                   408.0                    206.0                      74.0  \n",
      "6                     0.0                     16.0                       1.0  \n",
      "7                   317.0                      0.0                      70.0  \n",
      "8                     0.0                      6.0                       0.0  \n",
      "9                    59.0                     15.0                      11.0  \n",
      "10                    0.0                      3.0                      16.0  \n",
      "11                    0.0                      4.0                       1.0  \n"
     ]
    }
   ],
   "source": [
    "datasets_df = openml.datasets.list_datasets(output_format=\"dataframe\")\n",
    "print(datasets_df.head(n=10))\n",
    "\n",
    "datasets_df.set_index('did', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab886b-4b39-43c0-9840-84a5a89377ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cabf2478-c95e-4db1-83e4-6caae2677b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAHQCAYAAACRGHHiAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATlpJREFUeJzt3XlcTfn/B/BX3UpXlsr+ZcYMLUQoKTUhkT1LZYxtZF8yRpbs25Aa66Bs0TQzQjSFrGP52kmyxXwZMbYxikq0qe7t94dH9+eqECefrl7Px2Mej3HOvee8z7tz7n3dzzn3XK28vLw8EBEREQmkLboAIiIiIgYSIiIiEo6BhIiIiIRjICEiIiLhGEiIiIhIOAYSIiIiEo6BhIiIiIRjICEiIiLhGEhKsU/hnnWit0H0+ktLDUREpV2ZDyRxcXGYPHkynJyc0KRJE7Rr1w4zZ87E/fv3hdZ1+PBhTJkyRZJl/fLLL3B0dESTJk2wevXqQh9jbm6u9p+FhQXs7OwwePBgHDt27L3WK+U2FNejR48wcuRI/PPPPx91vebm5li1ahUAIDs7G35+foiKilLNnzp1KpydnYu1zJkzZ8LCwgKPHz8u8jFjxoyBo6MjFArF+xUO9dpFmzp1KszNzXHo0KFC5w8cOBADBw78KLVERETA3NwcDx48+CjrK453ObbzHThwAEOHDoWDgwOaNWuGbt26ITAwEGlpaWqPK037wYeS+m9348YN+Pj4oHXr1mjcuDGcnJwwYcIEXL58WZLlf4j81+5ly5YVOl+pVKJVq1YwNzdHREQEAODBgwdq/xatTAeS0NBQfPPNN0hKSsLEiRMRFBSEUaNGISYmBu7u7rh27Zqw2kJCQvDvv/9+8HLS0tLg7++Pxo0bY+PGjejVq1eRj/Xw8EBYWBjCwsLwyy+/YM6cOdDS0sKIESOwadOmYq9bqm14H6dPn8bRo0c/+nrDwsLQu3dvAEBiYiJCQkKQm5v7Qcv08PCAQqHAnj17Cp2fkpKC48ePw83NDTKZ7L3X82rtpcWcOXPw9OlT0WWUSu96bCuVSkycOBETJkxA7dq18cMPP2DNmjXo1q0bQkJCMGDAAKSmpn7k6j8OJycnhIWFoXr16h+8rJ07d8Ld3R1///03xo8fj+DgYEyYMAFPnjxB37598fPPP0tQ8YfR1tbG/v37C50XExODxMTEj1xR8eiILkCU2NhY+Pr6on///pgxY4Zqup2dHdq1awc3NzdMmzYNu3btEljlh0tNTYVSqYSLiwtatGjxxsfWrFkTzZo1U5vWuXNneHl5wd/fH05OTqhTp04JVqv5Xu+fVMs0MTHBrl274OnpWWD+7t27kZubCw8Pjw9eT2kil8uRmpqK+fPnY+nSpaLLKXXe9djesGEDdu/ejYCAALi4uKim29vbo2XLlujbty9WrVqFmTNnfoyyPypjY2MYGxt/8HL+/PNPzJgxA66urliwYIFa8O/evTt8fX3x448/wtzcHA4ODh+8vvdlbW2N8+fP49q1a2jUqJHavD179qBhw4b43//+J6i6tyuzIyQbN25ExYoVMWHChALzjI2NMXXqVHTo0EFtOHPv3r1wc3ODlZUVvvrqK8yePVvtk8WqVatgbm5eYHmvDoHmD5Ht27cP48aNg5WVFVq0aIEZM2YgPT0dwMvh6HPnzuHcuXMwNzdHdHR0kdtx6tQp9OvXD82bN4ednR0mTpyoGpWIiIhQnR6YPn16obW9jZaWFiZOnIicnByEh4erpj948AA+Pj5wdHREo0aNYG9vDx8fH6SkpLxxG65fv46xY8eiZcuWaNSoEVq1aoUFCxYgKytLtezTp0+jT58+qt6MGTMGt2/fVqvr0KFDcHNzg6WlJb766issWLAAGRkZqu2eNm0aAKBdu3aYOnUqAODatWsYNGgQmjdvDisrK3h6ehY51KpUKtGyZUssWLBANS0nJwdWVlbo06eP2mN79+6tOjWV/7d+8OAB2rVrBwCYNm1agdM0ERER6NixIywtLdG9e3ccP378jX+H/BG71/sAAJGRkbC1tcXnn3+OrKwsLF26FB06dEDjxo1hbW2NwYMHq70ITZ06FYMGDcKcOXNgY2ODXr16ITc3t8BQfWJiIqZNm4Y2bdqgSZMm8PDwwOHDh9XWXdjw/uvHQXJyMiZNmoSvvvoKlpaW6NGjB3bs2PHG7QVeHocjRozA7t27izx1k6+wUzjR0dFq+15ERAQsLS0RGxsLd3d3WFpaomPHjjhy5Ahu376NQYMGoWnTpnBxcSl0NOrChQvo2bMnLC0t4erqir1796rNf/HiBRYtWoQ2bdqgcePGhT7G2dkZCxcuxKBBg2BtbY3Zs2cXuU1SHNs5OTkIDg5G69at1cJIvmbNmmH8+PEwNTUtsg4pjtn79+9j9OjRsLOzQ9OmTdGnT58Cp4L/+usvjBw5EtbW1rC2toaXl1eBU+e//fYbOnXqBEtLS7Rq1Qpz584tcMrpVa+fspk6dSo8PT3x+++/o2PHjmjcuDG6d+/+1tPSa9euRfny5TFr1qxCRyEnT56MWrVqITAwUDXN2dkZy5cvh5+fH2xtbWFra4vJkyerXiPznT9/HgMGDEDTpk1ha2uLKVOmIDk5WW0bLCwscPnyZfTp0weWlpZwcnJCUFBQgTpsbW1RtWpV7Nu3T216bm4u/vjjD3Tt2vWN2ylamQwkeXl5OHnyJOzt7SGXywt9TKdOnTB27FhUqFABALB69Wp4e3ujadOmWLlyJby8vHDgwAEMHDhQ7cB8V3PmzEHt2rWxevVqDBs2DL///jvWrl2rmmdhYQELCwuEhYUVSLr5du7ciSFDhqBGjRpYtmwZpk2bhosXL6JPnz5ISkqCk5MTAgICAACjR49GWFhYsesEgPr166NWrVqIjY0FAGRmZuLbb7/FrVu3MGfOHGzcuBEDBgzA7t27VecvC9uGxMRE9O/fH5mZmfD390dQUBA6d+6M3377DSEhIQD+/4WrUaNGWLNmDRYsWIDbt29jxIgRUCqVAICoqCh4eXmhXr16CAwMxNixY7Fr1y6MGTMGeXl5cHJywujRowEAAQEBGDNmDNLS0jBs2DAYGRlh5cqVWL58OTIzMzF06FA8f/68wDZra2ujVatWOHPmjGra5cuXkZGRgatXr6rCT3JyMq5evYq2bduqPb969epqvc//fwD4999/sX79enz//fdYuXIl8vLy8N133yEpKanIv0HPnj2hq6tbYMQuPj4e165dU42O+Pj4IDw8HCNGjEBwcDCmTp2Kv/76C97e3moX154/fx53797FqlWr4OXlBR0d9cHSJ0+ewMPDA+fOnYO3tzdWrVqF2rVrw8vLq9ijhpMnT0Z8fDzmzZuH9evXw8LCAlOmTHlj0M43evRomJubY+7cuZKcusnNzcWECRPwzTffYPXq1ShXrhwmTZqEUaNGwcnJCStWrEC1atUwZcoUPHr0SO25s2bNQqdOnRAYGAgTExN4e3vj5MmTAF6+pnh5eWHr1q0YPHgw1qxZAysrK3h7excIX6Ghoaog16NHj0LrlOrYvnbtGlJSUgrsn68aOXJkgZCdT4pjVqlUYuTIkcjIyMCiRYuwevVqGBoaYsyYMbh79y4A4O+//1adPvf394evry/u37+Pvn37qo6LPXv24Mcff0T//v2xceNGeHl5YefOnWofGt7F1atXsXHjRowbNw6BgYHQ0dHBuHHjijxtpVQqcerUKbRs2RLly5cv9DF6enpo3749YmNj1QLH5s2bERsbi4ULF2LSpEk4fvw4hg0bpnoti4mJgaenJ/T19fHTTz9h+vTpOHfuHL799lu19xWlUonx48ejS5cuWL9+PZo3b44lS5bgxIkTanVoa2ujY8eOBU7bnDlzBi9evHjjflAalMlTNikpKXjx4sU7n35ITU3FmjVr0Lt3b8yZM0c13czMDP3790dERAT69etXrBratGmj+lRtb2+PU6dO4ejRo5g4cSJMTExUQaioYXSlUonFixfDwcEBy5cvV023trZGly5dEBwcjMmTJ6Nhw4YAgM8///yDhuSrVq2KJ0+eAADu3LmDmjVrwt/fH59//jkAoGXLloiLi8O5c+cAoNBtuHTpEho2bIgVK1ao5jk4OODMmTOIiYnBqFGjcOXKFWRlZWHkyJGoUaMGAKBWrVo4fPgwMjIyYGBggCVLlqBVq1ZYsmSJqr4vvvgCnp6eOHbsGJycnFR1NWzYEHXq1MGlS5eQnJyMgQMHonnz5gCAevXqYevWrUhLS0PFihULbLOTkxN27dqFxMREVK9eHWfPnkWjRo3w559/4sKFC3B0dMTJkychk8ng6Oio9lw9PT213ltYWKjmKZVKBAYGon79+gCAcuXKYfDgwbh06ZJqVOV1xsbGcHJywu7duzF+/HjV9MjISFSuXBkdO3ZEdnY20tPTMWvWLHTp0gXAy09M6enp8Pf3x+PHj1Xn0nNzczFv3jzUrVu30PX9/PPPSE5Oxr59+/DZZ58BeLnPenp6YtGiRejWrRu0td/t88y5c+cwZswYtG/fHsDL06KGhobvdL2Lrq4u/P390bt3byxYsEDtb/4+lEolRo0apbpW5tmzZ5gwYQIGDRqEwYMHA3i5r7u7u+Pq1auoWbOm6rleXl4YMWIEAKB169a4c+cOAgIC4OjoiNOnT+PEiRNYvny5qvetWrVCZmYmlixZgm7duqlCX/Xq1TF16tQi+yflsZ0fqt73VOtff/31wcdsZmYmbt26hVGjRqFNmzYAgCZNmiAgIAAvXrwA8PKDg76+PkJCQlTrsbe3R/v27bFhwwZVgK1duzb69+8PbW1t2Nraonz58gVGHN7m+fPniIiIUL1GlC9fHgMGDMDZs2fRsWPHAo9/+vQp0tLS3trDunXrIi8vD//++y+MjIwAvBxh/vnnn1WvL8bGxvDy8sLx48fh5OSEpUuX4ssvv8S6detUx0PTpk3RtWtX/P777+jfvz+Al4F3zJgxqv22efPmOHjwII4ePYpWrVqp1dGlSxeEhobi6tWraNy4MYCXo/vt2rWDvr5+sXr1sZXJEZL8F4J3/UbCpUuXkJ2dDVdXV7XpNjY2qF279jt90nvd6y8gNWvWVH3qfhd///03Hj9+XKCmzz//HFZWVu9V09toaWkBePkmv3nzZtSpUwf379/HiRMnEBwcjNu3byMnJ6fI5zs6OmLTpk0oV64c/v77b/z3v//F2rVrkZycjOzsbAAvD8Zy5crBw8MDfn5+OH36NBo0aABvb29UqFABt2/fxqNHj+Ds7Izc3FzVfy1atECFChVw6tSpQtdtamoKY2NjjB49GnPmzMGRI0dQrVo1+Pj4oFatWkXWK5PJcPr0aQAvP2W4uLigXr16iImJAQAcO3YMtra2qhfRd2FkZKQKIwBUb/iFjdS8ysPDA/fv38eFCxcAvHzjioqKgqurK8qVKwc9PT1s3LgRXbp0QWJiImJiYhAWFob//ve/AKD2t9HX11e9IBfm3LlzsLKyUtWWr3v37nj8+HGhp46KYmdnh1WrVuH7779HREQEkpOTMWXKFNjY2LzT8y0sLDB8+HBERUUVOGX0PqysrFT/X7VqVQDqx6OhoSGAl2HlVZ07d1b7d/v27XHp0iWkp6fjzJkz0NLSQps2bdT2S2dnZzx+/Bg3b95UPa9+/fpvDHNSHtv568n/RF5cUhyzVatWhYmJCWbNmoWpU6di7969yMvLw7Rp02BmZgYAOHv2LOzs7KCvr6/qXYUKFWBjY6M6/lq2bIk7d+7Azc0Nq1evxp9//glXV1cMGjSoWNtkbGystu/nh87MzMw3Pk9XV/eN8/MDxasjkW3btlX7sOPs7AxdXV2cP38emZmZuHz5Mtq0aYO8vDzVdn/22WeoX79+gdeyV/dbPT09GBsbF/qe0bx5c9SoUUN12iY7OxuHDh1Ct27d3lh/aVAmR0gMDQ1hYGCAhw8fFvmYjIwMZGdnw9DQUDWUl//i9aqqVau+9Y2kMK+fKtLW1i7W/Sryh6+LqunPP/8sdk1vkpCQoHae+eeff8a6deuQkpKCqlWrolGjRpDL5W/shVKpxLJlyxAaGoqMjAzUqlULTZo0Qbly5VSPqVOnDjZt2oT169dj27ZtCAkJQaVKldCvXz98//33qu2eN28e5s2bV2AdRV1FbmBggNDQUKxZswZ79+7F1q1bIZfL0b17d8yYMUOthnyVK1eGlZUVzpw5gw4dOuDy5cuYOHEiEhISEB0drRrK9fLyetc2AkCBYd/8oPe2N41WrVqhRo0aiIqKgrW1NU6fPo2EhAS1i1lPnDiBhQsX4vbt2zAwMIC5uTkMDAwAqL9QVqlSRbXewqSmphb6iTB/f3v9zfpNli9fjrVr12Lfvn3Yv38/tLW14eDggLlz5xYIPEUZM2YMDh8+rLru5UMUFh7f5ZNjtWrV1P5dpUoV5OXlIS0tDU+fPkVeXh6sra0LfW5iYqJqRKOwY/ZVUh7btWvXBoA3fv09OTkZBgYGhR4DUhyz2traCA4Oxpo1a3Dw4EFERkZCV1cX7du3x9y5c2FoaIinT59i7969Ba65AaC6KLVLly5QKpXYvHkzAgICsGLFCtSuXRsTJ04s1rURr7/2vu34MzIyQvny5d/61eH8611e/YDz+rd7tLW1YWhoiGfPnuHZs2dQKpUICgoq9HqQ1/8er++jRb1naGlpoVOnTti/fz8mT56MEydOQFtbG1999RUSEhLeuA2ilclAArxM/tHR0Xjx4kWhB2JERAR8fX2xefNmVK5cGcDL8+qvfrIFgMePH6teVPN3bIVCoUrL+ReqSi3/U1z+aZTXa8ofMpTCrVu3kJiYqDotFRUVBX9/f0ycOBEeHh6qF4zvv/8ecXFxRS5n/fr1CAkJwdy5c9GxY0fVJ4fXvx2SP5ybnZ2N2NhYhIWFYe3atTA3N1eFIh8fH9ja2hZYR/7fqjD16tXD4sWLoVAocOXKFezcuRNbtmxBnTp1VEPxr2vTpg02bdqE2NhY6OrqwtLSEgkJCQgPD8e5c+eQkpICJyenopsnIZlMhp49e2Lbtm2YMWMGduzYgUaNGqne6O7duwcvLy+0a9cO69atU30KDA0NLXCu+W0qV65c5L4FQG3/en2k8fVPbRUrVsTkyZMxefJk3L59G4cPH8bq1asxb948bNiw4Z3q0dPTg5+fH/r06QNfX99CH/O2Oj5Uamqq2pvCkydPIJPJULlyZVSsWBHly5fHr7/+Wuhzizo1Vhgpj+2GDRuiatWqOH78uGr4/3Vz587F2bNncfz48QJvelIcs126dEGNGjUwd+5czJkzB9evX8f+/fsRFBSEypUrY968eahYsSIcHBxUp81e9er1Td26dUO3bt3w/PlznDx5EkFBQZg8eTJsbGxUp4ukpqWlhbZt2+LkyZPIyMgo9DoShUKBQ4cOwdraWu1bPa9f96RQKJCSkgJjY2MYGBhAS0sLnp6ehQaqoq5vfBddunTBL7/8gri4OOzduxcdOnR46whPaVAmT9kAwJAhQ/D06VO1c7T5kpKSsGHDBtStWxfNmjVD06ZNoaenp3aDK+DlhYEPHz5UfSrK/+T16r038ofXi+tt5+e//PJLVKtWrUBN9+/fx6VLl4r8pPY+Vq5cCX19fdV9DmJjY1GxYkWMGDFCdfClp6cjNjZW7VPG69sQGxsLExMTeHh4qF7YEhIS8Ndff6meFxISAmdnZ2RnZ0NPTw/29vaYP38+gJd9rVevHqpUqYIHDx7A0tJS9V/NmjWxdOlS1afH19e9f/9+tGzZEo8fP4ZMJoOVlRXmzp2LSpUqFbh48VVOTk5ISEhAWFgYrK2toaurCzs7O+Tm5mLFihUwMzMr8lP+h9wTpCju7u54+vQpTp48iSNHjqjdN+Tq1at48eIFRo4cqTYknR9GijMC16JFC1y8eLHAtxx27dqFatWqqd5gK1SoUKB/r+7z//zzD9q0aaO6yK5evXoYPnw4HBwc3tj3wjRu3BjDhg3Dzp07C4wSvK0OKbwa6pRKJfbv34+mTZtCX18ftra2yMjIQF5entp+efPmTQQGBhbrXjRSHtva2trw9PTE0aNHCz3dFRMTgyNHjqBjx46FjhJJccxevHgRDg4OuHLlCrS0tNCwYUN4e3vDzMxM9TeztbVFfHw8GjZsqOpd48aNERISgoMHDwIAxo8fj7FjxwJ4GXI7d+6MMWPGQKFQlPj9NfIvyp07d26hIynLli3D3bt3MWrUKLXpJ06cUJ3aAl7eLDI3Nxf29vaoUKECLCwscPv2bbV9xtTUFAEBAR902r1Zs2aoXbs2oqKicOTIkVL/7Zp8ZXaEpFmzZvj+++/x008/4datW+jVqxeMjIxw8+ZNBAcHIz09HevXr4eWlhYMDQ0xYsQIBAQEQFdXF+3atcODBw+wYsUKmJiYwM3NDcDLT9N+fn6YNWsWhg8fjkePHiEgIEA1ZF4clSpVwsWLF3HmzBlYWFgU+OSvra2NCRMmYNq0afD29kbPnj2RkpKCgIAAVK5cudBPGm/z6NEjXLp0CcDLix4TEhIQGRmJkydP4ocfflCda23SpAm2bNkCf39/tG3bFomJidi4cSOePHmiVufr25B/N8n169ejWbNmuHv3LtatW4fs7GzV+duWLVtiyZIl8PLywoABAyCTybB161bo6emhbdu2kMlk8Pb2xuzZsyGTydC2bVs8e/YMq1evRkJCguobSZUqVQIAHDx4EK1bt4a1tTWUSqXqwkQDAwPs27cPz58/R4cOHYrsiZmZGWrXro2DBw9i4sSJAF4OIZuamuLChQsYOXJkkc/NfwE/c+YM6tevj6ZNmxb7b/K6unXrokWLFvDz84NCoVA7L9yoUSPo6Ohg8eLFGDJkCLKzsxEREaG6QVxxRgwGDx6MXbt2YfDgwRg7diyMjIywY8cOnD17FgsXLlQFPicnJ+zZswdNmjTBl19+icjISNU3J4CXpwxq1qyJBQsWIC0tDZ9//jmuXr2KY8eOvbF3RfHy8sLhw4fVrskAXp6rP3LkCHx9fVXfdniXrxYXx08//QSFQoFatWphy5Yt+Pvvv1U3w2rTpo3q665jxoxB/fr1ceXKFaxatQqOjo7FuheG1Me2p6cnYmJiMG7cOPTu3RtOTk7Q1tbG+fPn8dtvv8HU1LTIOypLcczWrl0b+vr68PHxwXfffYeqVavi9OnT+N///odvv/0WwMtTct988w1GjhyJvn37oly5cggLC8OhQ4ewcuVK1XrmzJmDH3/8Ea1bt8azZ88QEBCAL774Ag0aNChWT4rL3Nwc/v7+mDZtGu7du4dvvvkGderUQWJiIiIiInDq1ClMmjRJddFuvkePHmH06NH49ttv8e+//2LZsmVwdHSEnZ0dAGDChAkYMWIEJk6ciO7du0OhUCA4OBiXL19WfVPwfXXq1Am//vorDA0NCx1NftWpU6cKPQ3bqVMntQu7S1qZDSTAy6/LWVhYIDQ0FH5+fnj69Clq1qyJ1q1bY9SoUfjPf/6jemz+gbRp0yZs374dhoaG6NSpE8aPH68aWvvyyy/x448/Ys2aNRgxYgTq16+P+fPnqz4tFEf//v1x9epVDB8+HH5+fgUucAMANzc3GBgYYN26dfDy8kKFChXQqlUrTJgwocD57ncRHh6uuteIrq4uqlevjsaNG2PTpk1q5+179eqFBw8e4Pfff8fmzZtRo0YNtGnTBv369cOsWbMQHx8PExOTAtswcuRIpKSk4Ndff0VgYCBq1aqFHj16QEtLC+vWrUNqaioaNGiAtWvXIjAwEBMmTIBCoUDjxo0RHByMevXqAXh53w8DAwNs2LABYWFhKF++PKytrbFkyRLVaIWdnR0cHBywdOlSnDlzBuvXr8eGDRuwYsUKzJgxA5mZmTA1NcWqVavQsmXLN/aldevW2LJli9pBbWdnh7/++uuNp2sqVKiAwYMHIywsDEePHi3ygtvicnd3x5QpU9CzZ0+1C+bq1q2LpUuXIiAgAKNHj0blypXRrFkz/Pbbbxg4cCDOnz//zveiqVatGrZs2YKlS5fC19cXOTk5aNCgAVavXq32TaBp06YhNzcXixcvho6ODrp06YKJEyeq3WQrICAAy5Ytw4oVK5CSkoJatWph7NixRZ4me5NXT9283pN79+4hMjISYWFhsLW1xYoVK9C3b99ir6Movr6+WLRoEe7evQszMzMEBQWp9gltbW2sX78eK1aswLp165CUlIQaNWrA09Oz2NcYAdIe27q6uli9ejXCwsKwc+dO7Nu3D9nZ2ahTpw5GjhyJgQMHFvmhSapjNjg4WLUvPXv2DF988QV++OEH1Ye5Bg0aIDQ0FMuXL4ePjw/y8vJgZmaGwMBA1f72zTffICcnB1u3bsXmzZuhr68Pe3t7TJ48+aOcjujatSvMzc0REhKClStX4vHjxzA2NoaNjQ22bNlS6DedunbtikqVKmH8+PEoX748evXqBW9vb9V8R0dHbNy4EQEBARg3bhx0dXXRqFEj/Pzzzx98o8IuXbpg48aN6Ny581tH3Hfv3o3du3cXmN6wYcOPGki08vjLX0RERJJydnaGra0t/P39RZeiMcrsNSRERERUejCQEBERkXA8ZUNERETCcYSEiIiIhGMgISIiIuEYSIiIiEg4jbkPiVKpRG5uLrS1td/4GxxERERUeuTl5UGpVEJHR+eN90TRmECSm5v7xt9JISIiotLL0tISenp6Rc7XmECSn6osLS1L5DdCpKBQKBAXF1eqa9QU7KV02EtpsI/SYS+lowm9zK/xbXeM1ZhAkn+aRiaTldqm59OEGjUFeykd9lIa7KN02EvpaEIv33a5BS9qJSIiIuEYSIiIiEg4BhIiIiISjoGEiIiIhGMgISIiIuEYSIiIiEg4BhIiIiISjoGEiIiIhGMgISIiIuEYSIiIiEg4BhIiIiISjoGEiIiIhGMgISIiIuEYSIiIiEg4BhKJyeVy0SUQERFpnDIfSBRKhWTLkslksLCwgEwmk2yZgLQ1EhERlUY6ogsQTaYtg/ceb9xKuiW6lELVr1Ify7suF10GERFRiSrzgQQAbiXdwrXEa6LLICIiKrPK/CkbIiIiEo+BhIiIiIRjICEiIiLhGEiIiIhIOAYSIiIiEo6BhIiIiIRjICEiIiLhGEiIiIhIOAYSIiIiEo6BhIiIiIRjICEiIiLhGEiIiIhIOAYSIiIiEu69A0lycjJcXFwQHR2tmnb9+nUMGjQIVlZWcHBwgJ+fH3Jzc1XzIyMj4eLigmbNmsHNzQ0XL178sOqJiIjok/BegSQ2NhZ9+vTBvXv3VNOSk5Ph6ekJBwcHnDt3Dtu2bcPRo0fxyy+/AACio6Mxf/58+Pv7IyYmBt27d8fo0aORmZkpzZYQERGRxip2IImMjMSkSZPg7e2tNn3Hjh344osvMHLkSOjq6qJOnToIDg5G586dAQDbt29H165d0bx5c+jq6sLT0xNGRkbYu3evNFtCREREGkunuE9wdHSEq6srdHR01ELJlStXYGZmhtmzZ+Pw4cOQy+Vwd3fHyJEjAQDx8fFwd3dXW5aJiQmuX79erPUrFIrilvxGMplM0uWVFKm3u7TL396ytt0lgb2UBvsoHfZSOprQy3etrdiBpFq1aoVOT01NxaFDhzB37lzMmjULt27dwqhRo6Cnp4ehQ4ciPT0dcrlc7Tn6+vrIyMgo1vrj4uKKW3KR5HI5LCwsJFteSbpx40aZPL0l5d+7rGMvpcE+Soe9lM6n0MtiB5Ki6OnpwdLSEh4eHgCABg0aYMCAAdi3bx+GDh0KuVyOrKwstedkZWXByMioWOuxtLTUmFENKZmbm4su4aNSKBSIi4srs39vKbGX0mAfpcNeSkcTeplf49tIFkjq16+v9o0bAFAqlcjLywMAmJqa4ubNm2rz4+Pj0bp162KtRyaTldqml6SyuM1A2f17lwT2Uhrso3TYS+l8Cr2U7D4k7u7u+OuvvxAUFASFQoEbN25g06ZN6NGjBwDAw8MDUVFROHv2LHJychASEoKkpCS4uLhIVQIRERFpKElHSDZt2oRFixZh/fr10NfXR9++fTFw4EAAgL29PebMmYO5c+ciISEBJiYmCAoKgqGhoVQlEBERkYb6oEBy48YNtX83bdoUoaGhRT6+R48eqhETIiIiony8dTwREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCTceweS5ORkuLi4IDo6usC8xMREODg4ICIiQm16ZGQkXFxc0KxZM7i5ueHixYvvu3oiIiL6hLxXIImNjUWfPn1w7969AvOUSiUmTZqElJQUtenR0dGYP38+/P39ERMTg+7du2P06NHIzMx8v8qJiIjok1HsQBIZGYlJkybB29u70PmBgYGoWbMmatWqpTZ9+/bt6Nq1K5o3bw5dXV14enrCyMgIe/fufb/KiYiI6JOhU9wnODo6wtXVFTo6OgVCydmzZ7Fnzx78/vvvcHV1VZsXHx8Pd3d3tWkmJia4fv16sdavUCiKW/IbyWQySZdXUqTe7tIuf3vL2naXBPZSGuyjdNhL6WhCL9+1tmIHkmrVqhU6PSkpCdOnT8fKlSthYGBQYH56ejrkcrnaNH19fWRkZBRr/XFxccV6/JvI5XJYWFhItrySdOPGjTJ5ekvKv3dZx15Kg32UDnspnU+hl8UOJIXJy8uDj48PBg4ciMaNGxf6GLlcjqysLLVpWVlZMDIyKta6LC0tNWZUQ0rm5uaiS/ioFAoF4uLiyuzfW0rspTTYR+mwl9LRhF7m1/g2kgSSf//9F+fOncPly5cRGBgIAEhLS8O8efNw4MABrFu3Dqamprh586ba8+Lj49G6detirUsmk5XappeksrjNQNn9e5cE9lIa7KN02EvpfAq9lCSQ/Oc//ymQfpydnTF27Fi4ubkBADw8PODl5YXOnTujefPmCA0NRVJSElxcXKQogYiIiDSYJIHkXdjb22POnDmYO3cuEhISYGJigqCgIBgaGn6sEoiIiKiU+qBAcuPGjSLnHTlypMC0Hj16oEePHh+ySiIiIvoE8dbxREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCvXcgSU5OhouLC6Kjo1XTDhw4gB49esDa2hrOzs4ICAiAUqlUzY+MjISLiwuaNWsGNzc3XLx48cOqJyIiok/CewWS2NhY9OnTB/fu3VNNu3r1Knx8fDB+/HicP38eQUFBiIiIQEhICAAgOjoa8+fPh7+/P2JiYtC9e3eMHj0amZmZkmwIERERaa5iB5LIyEhMmjQJ3t7eatP/+ecffPPNN2jbti20tbVRv359uLi4ICYmBgCwfft2dO3aFc2bN4euri48PT1hZGSEvXv3SrMlREREpLF0ivsER0dHuLq6QkdHRy2UdOzYER07dlT9OysrC0ePHoWrqysAID4+Hu7u7mrLMjExwfXr14u1foVCUdyS30gmk0m6vJIi9XaXdvnbW9a2uySwl9JgH6XDXkpHE3r5rrUVO5BUq1btrY9JS0vD999/D319fXh6egIA0tPTIZfL1R6nr6+PjIyMYq0/Li6uWI9/E7lcDgsLC8mWV5Ju3LhRJk9vSfn3LuvYS2mwj9JhL6XzKfSy2IHkbW7fvo1x48ahSpUq+PXXX1GhQgUAL9/8s7Ky1B6blZUFIyOjYi3f0tJSY0Y1pGRubi66hI9KoVAgLi6uzP69pcReSoN9lA57KR1N6GV+jW8jaSA5duwYJkyYgK+//hoTJ06Ejs7/L97U1BQ3b95Ue3x8fDxat25drHXIZLJS2/SSVBa3GSi7f++SwF5Kg32UDnspnU+hl5Ldh+TSpUvw8vLCtGnTMGXKFLUwAgAeHh6IiorC2bNnkZOTg5CQECQlJcHFxUWqEoiIiEhDSTZCsnbtWuTm5sLX1xe+vr6q6c2bN8eGDRtgb2+POXPmYO7cuUhISICJiQmCgoJgaGgoVQlERESkoT4okNy4cUP1/2vXrn3r43v06IEePXp8yCqJiIjoE8RbxxMREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJlVpyuVx0CURE9JEwkJAkFEqFpMuTyWSwsLCATCaTdLlS10lERNLQEV0AfRpk2jJ47/HGraRbokspUv0q9bG863LRZQjB0SYiKu0YSEgyt5Ju4VriNdFlaDyFUgGZtnQjQ/mjTVKSukYiIgYSolKmtI82leWRJiIqOQwkRKUQR5uIqKzhRa1EREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCcdAQkRERMK9dyBJTk6Gi4sLoqOjVdMuX76M3r17w8rKCs7Ozti+fbvacyIjI+Hi4oJmzZrBzc0NFy9efP/KiYiI6JPxXoEkNjYWffr0wb1791TTUlNTMWLECPTs2RMxMTHw9fWFn58frly5AgCIjo7G/Pnz4e/vj5iYGHTv3h2jR49GZmamNFtCRFTC+JtARCWn2IEkMjISkyZNgre3t9r0P/74A4aGhujfvz90dHRgb28PV1dXhIaGAgC2b9+Orl27onnz5tDV1YWnpyeMjIywd+9eabaEiOg1Uv66M3+BmqhkFfvW8Y6OjnB1dYWOjo5aKLl58ybMzMzUHmtiYoLw8HAAQHx8PNzd3QvMv379+vvUTUT0VvxdICLNUexAUq1atUKnp6enFxjO1NfXR0ZGxjvNf1cKhbSfJqT+tFNSpN5uqWlKHwH2UiqlvY/Ay15qwu8CaUIvpZS/vWVtu0uCJvTyXWuT7Mf15HI5nj9/rjYtKysLBgYGqvlZWVkF5hsZGRVrPXFxcR9W6CvkcrnkP8teUm7cuFFqr7fRpD4C7KVUSnMfAfZSE0j5el7WfQq9lCyQmJmZ4dSpU2rT4uPjYWpqCgAwNTXFzZs3C8xv3bp1sdZjaWmpMZ8gpWRubi66hE8GeykN9lE6Za2XCoUCcXFxZfb1XEqa0Mv8Gt9GskDi4uKCxYsXIyQkBP3790dsbCyioqKwevVqAICHhwe8vLzQuXNnNG/eHKGhoUhKSoKLi0ux1iOTyUpt00tSWdzmksJeSoN9lE5Z7WVZfT0vCZ9CLyULJEZGRggODoavry9WrlwJY2NjzJw5Ey1btgQA2NvbY86cOZg7dy4SEhJgYmKCoKAgGBoaSlUCERERaagPCiQ3btxQ+7elpSW2bt1a5ON79OiBHj16fMgqiYiI6BPEW8cTERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERB+dXC4XXQKVMgwkRET0RgqlQtLlyWQyWFhYQCaTSbpcqeukj0tHdAFERFS6ybRl8N7jjVtJt0SXUqT6VepjedflossQ4lMZbWIgISKit7qVdAvXEq+JLkPjKZQKyLSlGxnKH22SktQ1visGEiIioo+ktI82iRxpYiAhIiL6iDjaVDhe1EpERETCMZAQERGRcAwkREREJJykgeTatWvo378/bGxs4OjoiAULFiA7OxsAcPnyZfTu3RtWVlZwdnbG9u3bpVw1ERERaTDJAolSqcTIkSPRsWNHnDt3DuHh4Th58iSCgoKQmpqKESNGoGfPnoiJiYGvry/8/Pxw5coVqVZPREREGkyyQJKamorHjx9DqVQiLy/v5cK1tSGXy/HHH3/A0NAQ/fv3h46ODuzt7eHq6orQ0FCpVk9EREQaTLKv/RoZGcHT0xM//vgjFi1aBIVCgXbt2sHT0xP+/v4wMzNTe7yJiQnCw8OLvR6FQvpbGGsCqbdbaprSR4C9lEpp7yPAXkpFU/oIsJdSkbKP77osyQKJUqmEvr4+Zs2aBQ8PD9y9exdjx47FypUrkZ6eXuDWtvr6+sjIyCj2euLi4qQqGXK5XPI73JWUGzduIDMzU3QZhdKkPgLspVRKcx8B9lIqmtRHgL2Uiog+ShZIDh48iAMHDmD//v0AAFNTU3h5ecHX1xeurq54/vy52uOzsrJgYGBQ7PVYWlpqTMKUkrm5uegSPhnspTTYR+mwl9JhL6UhZR8VCsU7DSZIFkj+/fdf1TdqVAvX0YGuri7MzMxw6tQptXnx8fEwNTUt9npkMlmZDCRlcZtLCnspDfZROuyldNhLaYjoo2QXtTo6OuLx48dYu3YtFAoF7t+/jzVr1sDV1RUuLi548uQJQkJCkJOTg7NnzyIqKgru7u5SrZ6IiIg0mGSBxMTEBOvWrcORI0dgZ2eHb7/9Fs7OzvD29oaRkRGCg4Oxf/9+2NnZYebMmZg5cyZatmwp1eqJiIhIg0n643oODg5wcHAodJ6lpSW2bt0q5eqIiIjoE8FbxxMREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCcdAQkRERMIxkBAREZFwDCREREQkHAMJERERCSdpIHn69Cl8fHxgZ2eHFi1aYMyYMUhMTAQAXL58Gb1794aVlRWcnZ2xfft2KVdNREREGkzSQPLdd98hIyMDBw8exH//+1/IZDLMmjULqampGDFiBHr27ImYmBj4+vrCz88PV65ckXL1REREpKF0pFrQ1atXcfnyZZw+fRoVKlQAAMyfPx+PHz/GH3/8AUNDQ/Tv3x8AYG9vD1dXV4SGhqJJkyZSlUBEREQaSrJAcuXKFZiYmGDbtm3YsmULMjMz0apVK0yZMgU3b96EmZmZ2uNNTEwQHh5e7PUoFAqpSgYAyGQySZdXUqTebqlpSh8B9lIqpb2PAHspFU3pI8BeSkXKPr7rsiQLJKmpqbhx4wYaN26MyMhIZGVlwcfHB1OmTEHVqlUhl8vVHq+vr4+MjIxirycuLk6qkiGXy2FhYSHZ8krSjRs3kJmZKbqMQmlSHwH2UiqluY8AeykVTeojwF5KRUQfJQskenp6AIAZM2agXLlyqFChAsaPH4+vv/4abm5uyMrKUnt8VlYWDAwMir0eS0tLjUmYUjI3NxddwieDvZQG+ygd9lI67KU0pOyjQqF4p8EEyQKJiYkJlEolcnJyUK5cOQCAUqkEADRs2BCbN29We3x8fDxMTU2LvR6ZTFYmA0lZ3OaSwl5Kg32UDnspHfZSGiL6KNm3bBwcHPDZZ59h+vTpSE9PR3JyMpYvX4727dujW7duePLkCUJCQpCTk4OzZ88iKioK7u7uUq2eiIiINJhkgURXVxe//fYbZDIZOnbsiI4dO6JmzZpYuHAhjIyMEBwcjP3798POzg4zZ87EzJkz0bJlS6lWT0RERBpMslM2AFCjRg0sX7680HmWlpbYunWrlKsjIiKiTwRvHU9ERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcAwkREREJBwDCREREQlXIoFEoVBg4MCBmDp1qmra5cuX0bt3b1hZWcHZ2Rnbt28viVUTERGRBiqRQBIQEIDz58+r/p2amooRI0agZ8+eiImJga+vL/z8/HDlypWSWD0RERFpGMkDyZkzZ/DHH3+gQ4cOqml//PEHDA0N0b9/f+jo6MDe3h6urq4IDQ2VevVERESkgXSkXFhSUhJmzJiB1atXIyQkRDX95s2bMDMzU3usiYkJwsPDi70OhULxoWWqkclkki6vpEi93VLTlD4C7KVUSnsfAfZSKprSR4C9lIqUfXzXZUkWSJRKJSZPnozBgwejQYMGavPS09Mhl8vVpunr6yMjI6PY64mLi/ugOl8ll8thYWEh2fJK0o0bN5CZmSm6jEJpUh8B9lIqpbmPAHspFU3qI8BeSkVEHyULJOvWrYOenh4GDhxYYJ5cLsfz58/VpmVlZcHAwKDY67G0tNSYhCklc3Nz0SV8MthLabCP0mEvpcNeSkPKPioUincaTJAskOzcuROJiYmwsbEB8DJwAMChQ4fg4+ODU6dOqT0+Pj4epqamxV6PTCYrk4GkLG5zSWEvpcE+Soe9lA57KQ0RfZTsotb9+/fjwoULOH/+PM6fP49u3bqhW7duOH/+PFxcXPDkyROEhIQgJycHZ8+eRVRUFNzd3aVaPREREWmwj3JjNCMjIwQHB2P//v2ws7PDzJkzMXPmTLRs2fJjrJ6IiIhKOUm/ZfMqf39/tX9bWlpi69atJbU6IiIi0mC8dTwREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXAMJERERCQcAwkREREJx0BCREREwjGQEBERkXCSBpLr169j8ODBsLW1xVdffQUfHx8kJycDAC5fvozevXvDysoKzs7O2L59u5SrJiIiIg0mWSDJysrCsGHDYGVlhZMnT2L37t14+vQppk+fjtTUVIwYMQI9e/ZETEwMfH194efnhytXrki1eiIiItJgkgWShw8fokGDBvDy8oKenh6MjIzQp08fxMTE4I8//oChoSH69+8PHR0d2Nvbw9XVFaGhoVKtnoiIiDSYjlQLqlevHjZs2KA27cCBA2jUqBFu3rwJMzMztXkmJiYIDw8v9noUCsUH1fk6mUwm6fJKitTbLTVN6SPAXkqltPcRYC+loil9BNhLqUjZx3ddlmSB5FV5eXn46aef8N///hebNm3Cr7/+CrlcrvYYfX19ZGRkFHvZcXFxUpUJuVwOCwsLyZZXkm7cuIHMzEzRZRRKk/oIsJdSKc19BNhLqWhSHwH2Uioi+ih5IElLS8O0adNw7do1bNq0Cebm5pDL5Xj+/Lna47KysmBgYFDs5VtaWmpMwpSSubm56BI+GeylNNhH6bCX0mEvpSFlHxUKxTsNJkgaSO7du4fhw4fjP//5D8LDw2FsbAwAMDMzw6lTp9QeGx8fD1NT02KvQyaTlclAUha3uaSwl9JgH6XDXkqHvZSGiD5KdlFramoqBg0aBGtra2zcuFEVRgDAxcUFT548QUhICHJycnD27FlERUXB3d1dqtUTERGRBpNshCQiIgIPHz7Evn37sH//frV5Fy9eRHBwMHx9fbFy5UoYGxtj5syZaNmypVSrJyIiIg0mWSAZPHgwBg8eXOR8S0tLbN26VarVERER0SeEt44nIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiEYyAhIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiEYyAhIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiEYyAhIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiEYyAhIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiEYyAhIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiEYyAhIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiEYyAhIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiE+6iBJCkpCWPGjIGNjQ3s7Ozg6+uL3Nzcj1kCERERlUIfNZCMHz8e5cuXx4kTJxAeHo4zZ84gJCTkY5ZAREREpdBHCyR3797FuXPnMHnyZMjlcnz22WcYM2YMQkNDP1YJREREVErpfKwV3bx5E4aGhqhRo4ZqWv369fHw4UM8e/YMlSpVeuPz8/LyAADZ2dmQyWSS1SWTydCgagPoaetJtkwp1TOuB4VCAYVCIbqUNyrtfQTYS6loSh8B9lIqpb2PAHsplZLoY/6y8t/Hi6KV97ZHSGTnzp1Yvnw5jh49qpp27949uLi44NixY6hZs+Ybn5+dnY24uLgSrpKIiIhKgqWlJfT0ig5iH22EpHz58sjMzFSblv9vAwODtz5fR0cHlpaW0NbWhpaWVonUSERERNLKy8uDUqmEjs6bI8dHCySmpqZ4+vQpnjx5gqpVqwIAbt26hZo1a6JixYpvfb62tvYbkxURERFpro92UesXX3yB5s2bY+HChUhLS8P9+/exevVqeHh4fKwSiIiIqJT6aNeQAMCTJ0/www8/IDo6Gtra2ujZsycmTZok6UWqREREpHk+aiAhIiIiKgxvHU9ERETCMZAQERGRcAwkREREJBwDCREREQnHQEJERETCMZAQERGRcB/tTq2fosTERGzbtg3Xr19HRkYGDAwMYGpqih49eqBu3bqiy6MyiPsklTbcJ6V17ty5Ar1s0aLFJ3E/L96H5D0dPXoU48ePR4sWLWBiYgJ9fX1kZWUhPj4eMTExWLVqFVq1aiW6TI3zKR9sJY37ZMngPvn+uE9K5++//8a4cePw8OFD1K1bF3K5HJmZmbh79y6qVq2K9evXa3zAYyB5T127dsXYsWPRuXPnAvP27t2LNWvWICoqSkBlmqksHGwljfuktLhPfjjuk9L59ttv0ahRI0ycOFHtR+pycnKwdOlSXL9+HSEhIeIKlAADyXuysrJCbGwstLULXoajUChga2uL2NhYAZVpprJwsJU07pPS4j754bhPSsfKygrR0dGF/sjsixcv4ODgoPG95EWt76lOnTo4evRoofMOHjyIzz777OMWpOHi4uLg7e1d4OepdXV14e3tjbi4OEGVaQ7uk9LiPvnhuE9Kp1KlSrh//36h8/7++28YGRl95Iqkx4ta39OkSZMwbtw42NjYwMzMDOXLl0dmZibi4+Nx7tw5BAYGii5Ro+QfbPXr1y8w71M52Eoa90lpcZ/8cNwnpTNgwAAMHToU/fr1g5mZGeRyObKysnDz5k1s2rQJnp6eokv8YDxl8wHu3LmDHTt2ID4+Hunp6ZDL5aqrx+vVqye6PI0SFBSE0NDQNx5sn8IBV9K4T0qH+6Q0uE9KJzIyEtu3by/QS3d3d3h4eIgu74MxkFCp8akfbKR5uE8SfTwMJCVk9+7d6Natm+gyiFS4T1Jpw31SOo8ePULNmjVFl/FBGEhKiJWVFS5evCi6jE/Gp3CwicZ9UlrcJz8c90npWFtb48KFC6LL+CAMJBJ6/vw55HJ5gavy6cN9CgebCBkZGdDV1YWurq7oUj453CepNDl//jxsbGxEl/FB+LXf9/TixQsEBARg8+bNyMrKwvDhw2Frawtra2vMnz8fOTk5okv8pKxfv150CaXelClTVP//7NkzjBo1CjY2NrCyssLs2bORnZ0tsLpPD/fJ92drayu6hE+OpocRgCMk723BggWIjo5GdnY2qlevDi0tLUyaNAnZ2dlYtGgRHB0dMW7cONFlUhny6if22bNn486dO5g8eTJevHiBJUuWoEmTJpg+fbrgKqksmTZtWqHTo6Ki4OrqCgDw8/P7mCVptLi4OGzevLnATxl4eHigRYsWosv7YDy38J7279+PHTt2IDk5GT169MDx48dRrVo1AMDy5cvx7bffMpDQR/XqZ4vjx49j69atqmscli1bht69ezOQFNOn/gZQ0h48eIALFy6gQ4cO0NfXV03X0tISWJVmCg8Ph5+fH1xdXeHu7q72u0CjR4/GzJkz0bNnT9FlfhAGkveUmZmJqlWromrVqqhevToqV66smle9enU8f/5cYHVUFr36Iq+tra12464aNWogKytLRFkaqyy8AZS0X375BatWrcKhQ4ewZMkSmJubAwAOHz7MkZFiWrt2LQIDA9GyZcsC8zp16oTZs2dr/P7IQPKe6tevjx07dqBnz544duyYanpubi6WLVsGS0tLgdVpniZNmrz1upv//e9/H6kazfTixQtMnz4djRs3hqmpKfbs2QM3NzcAQEhICExNTQVXqFnKwhtASdPW1sb3338PW1tbjBkzBkOGDEH//v1Fl6WRkpKSirz2xsbGBklJSR+5IukxkLwnb29vjBo1Ch06dED58uVV011dXfHixQsEBQUJrE7z/PLLLxg6dCjGjRsHCwsL0eVopMWLFyMuLg779u3DtWvXkJGRATc3NyxduhSbNm3iPllMZeEN4GOxt7fHtm3b4OPjg1OnTkGpVIouSeOYmpoiLCwMffv2LTBv8+bNMDMzE1CVtHhR6wdITk6GsbGx2rSLFy/C3NxcLaTQuwkPD0d4eDi2bt0quhSNl5eXh+TkZFSpUgU3btyAoaEhatSoIbosjfL111+jV69ehb4B/Prrr9i3bx+2bNkioDLNlZeXh7Vr12LXrl3Yt2+f6HI0yuXLlzFixAgYGRkV+F2gJ0+eIDg4GI0aNRJd5gdhIKFSZdq0aRg/fjzfPEm4svAGQJrl2bNnOHDggNpPGZiZmcHFxQWGhoaiy/tgDCREREX41N8ASHOkpKRg+vTpOH/+PBo1aoQZM2aoXRf2Kdyoj4GESoWYmJi3PoZfsySismrKlCl4+vQp+vTpg/379+PYsWMIDQ2FiYkJgE/jNvwMJFQqdOjQAffv30dRu6OWlha/ZUMfFUMylSaOjo7Ys2eP6hYTy5cvx+7duxEREYHKlStzhIRIKsnJyfjmm2/g7e2Nzp07iy6HiCGZShU7OzucPn0aMplMNe27775DRkYGNm7cyBESIinFxsZi8uTJOHToELS1+TNLJBZDMpUmQ4YMgbW1Nby8vFQ3QUxLS4OHhwesra2xb98+BhIiKe3YsQOtWrVClSpVRJdCxJBMpcb169cxfPhwNGzYUO2HHe/du4dBgwbh0aNHGj9ix0BCRPQGDMlUWrx48QIPHz7El19+qTb92bNniIiIgKenp5jCJMJAQkRERMJxDJKIiIiEYyAhIiIi4RhIiIiISDgGEiINYW5ujhEjRhS4L0ZERAScnZ1LZJ3Ozs6IiIiQdJlpaWlYunQpOnbsiGbNmsHBwQGjR49GbGys2uNiYmLg5OQEKysrbN68GQCQmJiIefPmwdnZGVZWVnBycsKcOXPw5MmTEq2ZiEoeAwmRBjl27Bg2bNgguoz3lpqaij59+uDSpUtYvHgxYmJicODAAdjZ2WHYsGFqQWLnzp1o2LAhLl68iH79+uHu3btwdXWFUqlEaGgoLl68iK1bt+Lp06fo27cv0tLSBG4ZEX0oBhIiDTJw4ECsWLGiyFtEP3jwAObm5njw4IFq2qpVqzBw4EAAL0dT+vXrhx9//BG2trZo2bIlfvvtN2zbtg1t27ZF8+bNMXv2bLVlXrt2DW5ubrC1tcXQoUNx584d1bx79+5h1KhRsLOzQ9u2bbF8+XJkZ2er1uXm5oYhQ4bAxsYGUVFRCAwMBABs3LgRTZo0ga6uLipWrAhPT09MmTIF8+bNQ0pKCsaNG4fIyEgcP34cVlZWyM7Ohq+vL5o0aYJ58+ahVq1aAICaNWti0aJFaNiwIW7evFmgHwkJCRg/fjycnZ3RtGlTtGvXDuHh4ar5mzdvRvv27WFjYwNXV1ds375drW9t2rSBra0t3N3dcfjwYbWeDBw4EC1atECHDh0QEhKiGrlKSEjAsGHDYGtri9atW2Ps2LFITEx8+x+XqIxjICHSIC4uLujTpw8mTJiAp0+fvtcyYmNjUaNGDZw9exbjxo2Dn58foqOjsXfvXoSEhCA8PFztd1wOHToEPz8/nDhxAnXq1MHIkSORm5uLjIwMeHp6wtTUFMePH8fmzZtx+vRprFq1SvXca9euwdXVFadPn4aLiwsOHTqEzp07Q09Pr0BdvXr1gkKhwLFjx7By5Uq4urrC1dVVdffJEydOoGvXrgWeV65cOaxcuRJWVlYF5s2cORO6urrYs2cPLly4gAEDBmD+/PlIT0/H/fv34efnh/Xr1+P8+fPw8fHB/PnzkZiYiLNnzyIsLAzbt29HdHQ0evfujRkzZiAnJwcJCQkYNGgQOnXqhNOnT2P16tXYvHkzwsLCAADLli1DzZo1cerUKezduxcZGRlqN7IiosIxkBBpmClTpsDY2BhTp04t8ndW3qR8+fIYNGgQtLW14ejoCIVCgaFDh0Iul8PS0hLVq1fHP//8o3r8kCFDYG5ujnLlymHq1Kl48OABrly5gqNHjyI7OxsTJkxAuXLlUKtWLXz//fcIDQ1VPVdXVxc9evSAnp4e9PX1kZiYiGrVqhVaV7ly5VC5cuVCRxNSU1OhVCqLfG5RFixYgDlz5kBXVxcPHz6EgYEBsrKykJqaCplMhry8PGzduhWxsbGwt7fHpUuXUL16dZQrVw6pqanYtm0b/vzzT/Tu3RtnzpyBrq4udu3ahfr166N///7Q1dWFiYkJhg4dqtrucuXKITY2Fnv27EF6ejo2bNiAmTNnFqtuorJIR3QBRFQ8enp6+Omnn9CrVy8EBwfDyMioWM83NDRU/RZG/u3QK1WqpJqvra0NpVKp+nedOnVU/y+Xy2FoaIiEhAT8888/SE5OVvvF27y8POTk5CApKQkAUK1aNbVbrlerVg0PHz4stK7MzEwkJSUVGjoMDQ2hq6uLx48fF/rcpKQkGBsbq7Yr3/3797Fo0SLcuXMHX3zxBerWrQsAUCqVqFOnDn777Tds2LABo0aNgkKhgJubGyZPngwrKyusWrVKNV9fXx8DBw7E6NGj8c8//+DatWuwsbFRrUepVKp+9GzmzJlYt24dNm7ciKlTp6JBgwaYOXOm2uOJqCAGEiIN9Pnnn2P+/Pnw8fGBm5ubanr+m2JOTo5qWkpKitpzX3/TfptXRyzS0tKQkpKC2rVrIzc3F59//jn279+vNj8/HBS2rk6dOmHPnj0YNWoU5HK52rzw8HDo6emhTZs2BWrQ1dWFo6Mj9u7di549e6rNy87ORo8ePTBw4ECMHDlSNT0nJwcjR47EhAkT0K9fP2hpaeHq1avYtWsXgJchRqFQIDAwEEqlEhcuXMC4cePw5Zdfom3btqhSpQo2btyI7OxsnDlzBmPHjkWjRo1Qs2ZN2NnZYePGjap1paSkID09HQDw559/ok+fPvjuu++QnJyMwMBAjB07FmfPni1O24nKHJ6yIdJQXbp0gbu7u+raBQCoUqUKKleujD179iAvLw/Xrl1TCwzvIzg4GLdv30ZmZiZ8fX3RsGFDNG7cGG3btlWdksjOzsazZ88wZcoUeHt7Fxl6vLy8IJfLMXz4cMTFxSE3NxfJycn4+eefsXTpUsyaNUsVZl7n4+OD2NhYzJ8/HwkJCQCAO3fuYOzYsTAwMECfPn3UHp+Tk4OsrCzo6+tDS0sLDx8+xOLFi1XzHj58iCFDhuDMmTPQ1tZGjRo1AABGRkaIi4vDsGHDcP36dejp6al+x8bIyAiurq64dOkSdu3ahdzcXCQmJmLUqFHw9/cHAKxduxbz589HWloaKlWqBLlcXuxRLKKyiCMkRBps+vTpuHz5Mp49ewbg5emc+fPnY+XKldi4cSMaN26Mr7/+usA9Poqjffv2GDVqFFJSUtCiRQusXr0a2traqFChAkJCQuDv748NGzZAqVTCzs4Oa9asKXJZFSpUQFhYGIKCguDj44NHjx5BT08PVlZWCAoKUjv987p69eohPDwcgYGB8PDwQFpaGgwNDdGmTRssXLgQhoaGao8vX748Fi5ciBUrVmDBggWoUqUKvv76a8THx+Ovv/5Cx44dMXv2bMydOxeJiYmoWLEi+vXrh86dO0NLSwt37tzB6NGjkZKSgipVqmD69Olo2rQpAGDDhg1YsmQJFixYAJlMBicnJ8yYMQMA8MMPP2DevHlo164dsrOz0bhxY6xYseK9+09UVvDH9YiIiEg4nrIhIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiEYyAhIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiEYyAhIiIi4RhIiIiISDgGEiIiIhKOgYSIiIiE+z9K5IUJa4zbvgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets_df[datasets_df['NumberOfClasses'] > 2]['NumberOfClasses'].value_counts()[:20].plot(kind = 'bar', color='forestgreen')\n",
    "\n",
    "plt.title('Count of Datasets with Various Number of Classes in OpenML')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390445e6-2a5b-41fc-a0fe-74d1ec32c590",
   "metadata": {},
   "source": [
    "#### `Dataset Selection`: Information Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f3750a7-58ba-44bd-a03c-474df21343f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                  Satellite\n",
       "version                                       1\n",
       "uploader                                   3768\n",
       "status                                   active\n",
       "format                                     ARFF\n",
       "MajorityClassSize                        5025.0\n",
       "MaxNominalAttDistinctValues                 2.0\n",
       "MinorityClassSize                          75.0\n",
       "NumberOfClasses                             2.0\n",
       "NumberOfFeatures                           37.0\n",
       "NumberOfInstances                        5100.0\n",
       "NumberOfInstancesWithMissingValues          0.0\n",
       "NumberOfMissingValues                       0.0\n",
       "NumberOfNumericFeatures                    36.0\n",
       "NumberOfSymbolicFeatures                    1.0\n",
       "Name: 40900, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_df.loc[40900]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295812f-8f5c-4a4a-8fef-d6c07413a273",
   "metadata": {},
   "source": [
    "#### Satellite Dataset `https://www.openml.org/d/182`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e20174-4396-44c8-a549-cd5cc7985bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is dataset 'satimage', the target feature is 'class'\n",
      "URL: https://api.openml.org/data/v1/download/3619/satimage.arff\n",
      "**Author**: Ashwin Srinivasan, Department of Statistics and Data Modeling, University of Strathclyde  \n",
      "**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite)) - 1993  \n",
      "**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  \n",
      "\n",
      "The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classifica\n"
     ]
    }
   ],
   "source": [
    "dataset = openml.datasets.get_dataset( 182)\n",
    "\n",
    "# Sumamry Print\n",
    "print(\n",
    "    f\"This is dataset '{dataset.name}', the target feature is \"\n",
    "    f\"'{dataset.default_target_attribute}'\"\n",
    ")\n",
    "print(f\"URL: {dataset.url}\")\n",
    "print(dataset.description[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e910107-5c1a-42b1-b5b9-87e9af703601",
   "metadata": {},
   "source": [
    "#### OpenML API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ecfe69d-822a-49ae-878b-faf7bc8da466",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "    dataset_format=\"array\", target=dataset.default_target_attribute\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(X, columns=attribute_names)\n",
    "df[\"class\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602f32ff-f95b-43c1-a4ac-324f36895985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aattr</th>\n",
       "      <th>Battr</th>\n",
       "      <th>Cattr</th>\n",
       "      <th>Dattr</th>\n",
       "      <th>Eattr</th>\n",
       "      <th>Fattr</th>\n",
       "      <th>A1attr</th>\n",
       "      <th>B2attr</th>\n",
       "      <th>C3attr</th>\n",
       "      <th>D4attr</th>\n",
       "      <th>E5attr</th>\n",
       "      <th>F6attr</th>\n",
       "      <th>A7attr</th>\n",
       "      <th>B8attr</th>\n",
       "      <th>C9attr</th>\n",
       "      <th>D10attr</th>\n",
       "      <th>E11attr</th>\n",
       "      <th>F12attr</th>\n",
       "      <th>A13attr</th>\n",
       "      <th>B14attr</th>\n",
       "      <th>C15attr</th>\n",
       "      <th>D16attr</th>\n",
       "      <th>E17attr</th>\n",
       "      <th>F18attr</th>\n",
       "      <th>A19attr</th>\n",
       "      <th>B20attr</th>\n",
       "      <th>C21attr</th>\n",
       "      <th>D22attr</th>\n",
       "      <th>E23attr</th>\n",
       "      <th>F24attr</th>\n",
       "      <th>A25attr</th>\n",
       "      <th>B26attr</th>\n",
       "      <th>C27attr</th>\n",
       "      <th>D28attr</th>\n",
       "      <th>E29attr</th>\n",
       "      <th>F30attr</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117596</td>\n",
       "      <td>1.241362</td>\n",
       "      <td>1.184036</td>\n",
       "      <td>0.815302</td>\n",
       "      <td>-0.158561</td>\n",
       "      <td>1.256483</td>\n",
       "      <td>1.193546</td>\n",
       "      <td>0.818486</td>\n",
       "      <td>-0.141965</td>\n",
       "      <td>0.879481</td>\n",
       "      <td>0.670010</td>\n",
       "      <td>0.401020</td>\n",
       "      <td>0.052220</td>\n",
       "      <td>1.204523</td>\n",
       "      <td>1.181239</td>\n",
       "      <td>0.758245</td>\n",
       "      <td>-0.151111</td>\n",
       "      <td>1.214967</td>\n",
       "      <td>1.187378</td>\n",
       "      <td>0.598708</td>\n",
       "      <td>-0.136658</td>\n",
       "      <td>1.011130</td>\n",
       "      <td>0.899623</td>\n",
       "      <td>0.761977</td>\n",
       "      <td>-0.085593</td>\n",
       "      <td>1.211546</td>\n",
       "      <td>1.251179</td>\n",
       "      <td>0.807707</td>\n",
       "      <td>-0.069968</td>\n",
       "      <td>1.219160</td>\n",
       "      <td>1.250463</td>\n",
       "      <td>0.597678</td>\n",
       "      <td>-0.054291</td>\n",
       "      <td>1.233342</td>\n",
       "      <td>1.262255</td>\n",
       "      <td>0.603258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.205362</td>\n",
       "      <td>-1.249654</td>\n",
       "      <td>-0.077532</td>\n",
       "      <td>0.444886</td>\n",
       "      <td>-0.895959</td>\n",
       "      <td>-0.447579</td>\n",
       "      <td>-0.786760</td>\n",
       "      <td>-0.554203</td>\n",
       "      <td>-0.364672</td>\n",
       "      <td>0.092157</td>\n",
       "      <td>-0.051291</td>\n",
       "      <td>-0.178503</td>\n",
       "      <td>-0.976988</td>\n",
       "      <td>-0.852379</td>\n",
       "      <td>-0.498640</td>\n",
       "      <td>0.124397</td>\n",
       "      <td>-0.668189</td>\n",
       "      <td>-0.836981</td>\n",
       "      <td>-0.487496</td>\n",
       "      <td>-0.084225</td>\n",
       "      <td>-0.656748</td>\n",
       "      <td>-0.343506</td>\n",
       "      <td>-0.176313</td>\n",
       "      <td>-0.234313</td>\n",
       "      <td>-0.748307</td>\n",
       "      <td>-0.981173</td>\n",
       "      <td>-0.614884</td>\n",
       "      <td>-0.192752</td>\n",
       "      <td>-0.736996</td>\n",
       "      <td>-0.969292</td>\n",
       "      <td>-0.844805</td>\n",
       "      <td>-0.400030</td>\n",
       "      <td>-0.725852</td>\n",
       "      <td>-0.344432</td>\n",
       "      <td>-0.594534</td>\n",
       "      <td>-0.183967</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.779075</td>\n",
       "      <td>0.148811</td>\n",
       "      <td>0.042617</td>\n",
       "      <td>-0.243030</td>\n",
       "      <td>0.800057</td>\n",
       "      <td>0.164136</td>\n",
       "      <td>0.053370</td>\n",
       "      <td>-0.448612</td>\n",
       "      <td>0.154978</td>\n",
       "      <td>-0.345245</td>\n",
       "      <td>-0.712483</td>\n",
       "      <td>-0.441923</td>\n",
       "      <td>0.713854</td>\n",
       "      <td>0.504301</td>\n",
       "      <td>-0.198662</td>\n",
       "      <td>-0.403809</td>\n",
       "      <td>0.735308</td>\n",
       "      <td>0.341798</td>\n",
       "      <td>-0.188412</td>\n",
       "      <td>-0.399425</td>\n",
       "      <td>0.160536</td>\n",
       "      <td>-0.343506</td>\n",
       "      <td>-0.355636</td>\n",
       "      <td>-0.181877</td>\n",
       "      <td>0.650756</td>\n",
       "      <td>-0.016376</td>\n",
       "      <td>-0.915862</td>\n",
       "      <td>-0.877277</td>\n",
       "      <td>0.671174</td>\n",
       "      <td>-0.006373</td>\n",
       "      <td>-0.425752</td>\n",
       "      <td>-0.662584</td>\n",
       "      <td>0.691889</td>\n",
       "      <td>0.356801</td>\n",
       "      <td>-0.175259</td>\n",
       "      <td>-0.236449</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.146564</td>\n",
       "      <td>0.585831</td>\n",
       "      <td>0.342991</td>\n",
       "      <td>0.021553</td>\n",
       "      <td>0.947536</td>\n",
       "      <td>0.601074</td>\n",
       "      <td>0.353416</td>\n",
       "      <td>0.026550</td>\n",
       "      <td>1.788164</td>\n",
       "      <td>1.010702</td>\n",
       "      <td>0.910444</td>\n",
       "      <td>0.401020</td>\n",
       "      <td>1.375487</td>\n",
       "      <td>0.810648</td>\n",
       "      <td>0.941256</td>\n",
       "      <td>0.230039</td>\n",
       "      <td>1.104649</td>\n",
       "      <td>1.214967</td>\n",
       "      <td>0.409758</td>\n",
       "      <td>0.230975</td>\n",
       "      <td>1.126416</td>\n",
       "      <td>1.011130</td>\n",
       "      <td>0.720300</td>\n",
       "      <td>0.237614</td>\n",
       "      <td>1.387105</td>\n",
       "      <td>0.860711</td>\n",
       "      <td>0.528832</td>\n",
       "      <td>0.281150</td>\n",
       "      <td>1.412317</td>\n",
       "      <td>1.044084</td>\n",
       "      <td>0.532085</td>\n",
       "      <td>0.282612</td>\n",
       "      <td>1.438068</td>\n",
       "      <td>1.058033</td>\n",
       "      <td>0.842981</td>\n",
       "      <td>0.130923</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.764376</td>\n",
       "      <td>-1.162250</td>\n",
       "      <td>-0.137607</td>\n",
       "      <td>0.180303</td>\n",
       "      <td>-0.969698</td>\n",
       "      <td>-1.146681</td>\n",
       "      <td>-0.126658</td>\n",
       "      <td>0.184937</td>\n",
       "      <td>-0.735851</td>\n",
       "      <td>-1.132569</td>\n",
       "      <td>-0.111399</td>\n",
       "      <td>0.190284</td>\n",
       "      <td>-1.197532</td>\n",
       "      <td>-1.202490</td>\n",
       "      <td>-0.138666</td>\n",
       "      <td>0.388501</td>\n",
       "      <td>-0.668189</td>\n",
       "      <td>-1.186248</td>\n",
       "      <td>-0.367863</td>\n",
       "      <td>0.230975</td>\n",
       "      <td>-0.879643</td>\n",
       "      <td>-0.998975</td>\n",
       "      <td>-0.355636</td>\n",
       "      <td>-0.129441</td>\n",
       "      <td>-0.895577</td>\n",
       "      <td>-1.244299</td>\n",
       "      <td>-0.795470</td>\n",
       "      <td>-0.192752</td>\n",
       "      <td>-0.885225</td>\n",
       "      <td>-1.231906</td>\n",
       "      <td>-0.784941</td>\n",
       "      <td>-0.347519</td>\n",
       "      <td>-0.875088</td>\n",
       "      <td>-1.220973</td>\n",
       "      <td>-0.774223</td>\n",
       "      <td>-0.551339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Aattr     Battr     Cattr     Dattr     Eattr     Fattr    A1attr  \\\n",
       "0  0.117596  1.241362  1.184036  0.815302 -0.158561  1.256483  1.193546   \n",
       "1 -1.205362 -1.249654 -0.077532  0.444886 -0.895959 -0.447579 -0.786760   \n",
       "2  0.779075  0.148811  0.042617 -0.243030  0.800057  0.164136  0.053370   \n",
       "3  1.146564  0.585831  0.342991  0.021553  0.947536  0.601074  0.353416   \n",
       "4 -0.764376 -1.162250 -0.137607  0.180303 -0.969698 -1.146681 -0.126658   \n",
       "\n",
       "     B2attr    C3attr    D4attr    E5attr    F6attr    A7attr    B8attr  \\\n",
       "0  0.818486 -0.141965  0.879481  0.670010  0.401020  0.052220  1.204523   \n",
       "1 -0.554203 -0.364672  0.092157 -0.051291 -0.178503 -0.976988 -0.852379   \n",
       "2 -0.448612  0.154978 -0.345245 -0.712483 -0.441923  0.713854  0.504301   \n",
       "3  0.026550  1.788164  1.010702  0.910444  0.401020  1.375487  0.810648   \n",
       "4  0.184937 -0.735851 -1.132569 -0.111399  0.190284 -1.197532 -1.202490   \n",
       "\n",
       "     C9attr   D10attr   E11attr   F12attr   A13attr   B14attr   C15attr  \\\n",
       "0  1.181239  0.758245 -0.151111  1.214967  1.187378  0.598708 -0.136658   \n",
       "1 -0.498640  0.124397 -0.668189 -0.836981 -0.487496 -0.084225 -0.656748   \n",
       "2 -0.198662 -0.403809  0.735308  0.341798 -0.188412 -0.399425  0.160536   \n",
       "3  0.941256  0.230039  1.104649  1.214967  0.409758  0.230975  1.126416   \n",
       "4 -0.138666  0.388501 -0.668189 -1.186248 -0.367863  0.230975 -0.879643   \n",
       "\n",
       "    D16attr   E17attr   F18attr   A19attr   B20attr   C21attr   D22attr  \\\n",
       "0  1.011130  0.899623  0.761977 -0.085593  1.211546  1.251179  0.807707   \n",
       "1 -0.343506 -0.176313 -0.234313 -0.748307 -0.981173 -0.614884 -0.192752   \n",
       "2 -0.343506 -0.355636 -0.181877  0.650756 -0.016376 -0.915862 -0.877277   \n",
       "3  1.011130  0.720300  0.237614  1.387105  0.860711  0.528832  0.281150   \n",
       "4 -0.998975 -0.355636 -0.129441 -0.895577 -1.244299 -0.795470 -0.192752   \n",
       "\n",
       "    E23attr   F24attr   A25attr   B26attr   C27attr   D28attr   E29attr  \\\n",
       "0 -0.069968  1.219160  1.250463  0.597678 -0.054291  1.233342  1.262255   \n",
       "1 -0.736996 -0.969292 -0.844805 -0.400030 -0.725852 -0.344432 -0.594534   \n",
       "2  0.671174 -0.006373 -0.425752 -0.662584  0.691889  0.356801 -0.175259   \n",
       "3  1.412317  1.044084  0.532085  0.282612  1.438068  1.058033  0.842981   \n",
       "4 -0.885225 -1.231906 -0.784941 -0.347519 -0.875088 -1.220973 -0.774223   \n",
       "\n",
       "    F30attr  class  \n",
       "0  0.603258      0  \n",
       "1 -0.183967      4  \n",
       "2 -0.236449      5  \n",
       "3  0.130923      2  \n",
       "4 -0.551339      4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb67f42-aa5d-4087-a527-8a4ba147f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    1531\n",
       "5    1508\n",
       "2    1356\n",
       "4     707\n",
       "1     703\n",
       "3     625\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "664c86c4-6640-4cfe-baf9-538bd7744191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aattr</th>\n",
       "      <th>Battr</th>\n",
       "      <th>Cattr</th>\n",
       "      <th>Dattr</th>\n",
       "      <th>Eattr</th>\n",
       "      <th>Fattr</th>\n",
       "      <th>A1attr</th>\n",
       "      <th>B2attr</th>\n",
       "      <th>C3attr</th>\n",
       "      <th>D4attr</th>\n",
       "      <th>E5attr</th>\n",
       "      <th>F6attr</th>\n",
       "      <th>A7attr</th>\n",
       "      <th>B8attr</th>\n",
       "      <th>C9attr</th>\n",
       "      <th>D10attr</th>\n",
       "      <th>E11attr</th>\n",
       "      <th>F12attr</th>\n",
       "      <th>A13attr</th>\n",
       "      <th>B14attr</th>\n",
       "      <th>C15attr</th>\n",
       "      <th>D16attr</th>\n",
       "      <th>E17attr</th>\n",
       "      <th>F18attr</th>\n",
       "      <th>A19attr</th>\n",
       "      <th>B20attr</th>\n",
       "      <th>C21attr</th>\n",
       "      <th>D22attr</th>\n",
       "      <th>E23attr</th>\n",
       "      <th>F24attr</th>\n",
       "      <th>A25attr</th>\n",
       "      <th>B26attr</th>\n",
       "      <th>C27attr</th>\n",
       "      <th>D28attr</th>\n",
       "      <th>E29attr</th>\n",
       "      <th>F30attr</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "      <td>6430.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000846</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>-0.000272</td>\n",
       "      <td>-0.000863</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>-0.000611</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>-0.000779</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>-0.000760</td>\n",
       "      <td>-0.000536</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-0.000599</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>-0.000579</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>-0.000710</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>2.435148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.999648</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>1.000202</td>\n",
       "      <td>0.999697</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>1.000220</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>1.000201</td>\n",
       "      <td>0.999639</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>1.000095</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>1.000126</td>\n",
       "      <td>1.000260</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1.000072</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>1.000039</td>\n",
       "      <td>1.000009</td>\n",
       "      <td>1.000191</td>\n",
       "      <td>1.000274</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>1.000023</td>\n",
       "      <td>1.000017</td>\n",
       "      <td>1.000276</td>\n",
       "      <td>0.999877</td>\n",
       "      <td>1.000010</td>\n",
       "      <td>1.000005</td>\n",
       "      <td>1.000286</td>\n",
       "      <td>1.876348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.234329</td>\n",
       "      <td>-2.473310</td>\n",
       "      <td>-2.780894</td>\n",
       "      <td>-2.624275</td>\n",
       "      <td>-2.223275</td>\n",
       "      <td>-2.457498</td>\n",
       "      <td>-2.947095</td>\n",
       "      <td>-2.824420</td>\n",
       "      <td>-2.146330</td>\n",
       "      <td>-2.444776</td>\n",
       "      <td>-2.936494</td>\n",
       "      <td>-2.812701</td>\n",
       "      <td>-2.226740</td>\n",
       "      <td>-2.471642</td>\n",
       "      <td>-2.958463</td>\n",
       "      <td>-2.833559</td>\n",
       "      <td>-2.145554</td>\n",
       "      <td>-2.452344</td>\n",
       "      <td>-2.939991</td>\n",
       "      <td>-2.815957</td>\n",
       "      <td>-2.217016</td>\n",
       "      <td>-2.441006</td>\n",
       "      <td>-2.925927</td>\n",
       "      <td>-2.803693</td>\n",
       "      <td>-2.221005</td>\n",
       "      <td>-2.472222</td>\n",
       "      <td>-2.962511</td>\n",
       "      <td>-2.825539</td>\n",
       "      <td>-2.219281</td>\n",
       "      <td>-2.457440</td>\n",
       "      <td>-2.940074</td>\n",
       "      <td>-2.815531</td>\n",
       "      <td>-2.218211</td>\n",
       "      <td>-2.448131</td>\n",
       "      <td>-2.930494</td>\n",
       "      <td>-2.808050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.690878</td>\n",
       "      <td>-0.550421</td>\n",
       "      <td>-0.858503</td>\n",
       "      <td>-0.719279</td>\n",
       "      <td>-0.674739</td>\n",
       "      <td>-0.534967</td>\n",
       "      <td>-0.846770</td>\n",
       "      <td>-0.712591</td>\n",
       "      <td>-0.661615</td>\n",
       "      <td>-0.520206</td>\n",
       "      <td>-0.832700</td>\n",
       "      <td>-0.758027</td>\n",
       "      <td>-0.682928</td>\n",
       "      <td>-0.546032</td>\n",
       "      <td>-0.858614</td>\n",
       "      <td>-0.720733</td>\n",
       "      <td>-0.668189</td>\n",
       "      <td>-0.531371</td>\n",
       "      <td>-0.846398</td>\n",
       "      <td>-0.714624</td>\n",
       "      <td>-0.656748</td>\n",
       "      <td>-0.518297</td>\n",
       "      <td>-0.833829</td>\n",
       "      <td>-0.758677</td>\n",
       "      <td>-0.674672</td>\n",
       "      <td>-0.542629</td>\n",
       "      <td>-0.855666</td>\n",
       "      <td>-0.719309</td>\n",
       "      <td>-0.662882</td>\n",
       "      <td>-0.531602</td>\n",
       "      <td>-0.844805</td>\n",
       "      <td>-0.715095</td>\n",
       "      <td>-0.651234</td>\n",
       "      <td>-0.519740</td>\n",
       "      <td>-0.834119</td>\n",
       "      <td>-0.761265</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.102897</td>\n",
       "      <td>0.148811</td>\n",
       "      <td>0.102692</td>\n",
       "      <td>-0.084280</td>\n",
       "      <td>-0.084821</td>\n",
       "      <td>0.076748</td>\n",
       "      <td>0.113379</td>\n",
       "      <td>-0.079042</td>\n",
       "      <td>-0.141965</td>\n",
       "      <td>0.092157</td>\n",
       "      <td>0.068926</td>\n",
       "      <td>-0.073135</td>\n",
       "      <td>-0.094810</td>\n",
       "      <td>0.066663</td>\n",
       "      <td>0.101317</td>\n",
       "      <td>-0.086885</td>\n",
       "      <td>-0.077243</td>\n",
       "      <td>0.079847</td>\n",
       "      <td>0.050856</td>\n",
       "      <td>-0.084225</td>\n",
       "      <td>-0.136658</td>\n",
       "      <td>0.049776</td>\n",
       "      <td>0.062784</td>\n",
       "      <td>-0.077004</td>\n",
       "      <td>-0.085593</td>\n",
       "      <td>0.071332</td>\n",
       "      <td>0.047268</td>\n",
       "      <td>-0.087440</td>\n",
       "      <td>-0.069968</td>\n",
       "      <td>0.081165</td>\n",
       "      <td>0.053167</td>\n",
       "      <td>-0.084964</td>\n",
       "      <td>-0.128909</td>\n",
       "      <td>0.050011</td>\n",
       "      <td>0.064327</td>\n",
       "      <td>-0.079004</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.779075</td>\n",
       "      <td>0.848043</td>\n",
       "      <td>0.823588</td>\n",
       "      <td>0.497802</td>\n",
       "      <td>0.800057</td>\n",
       "      <td>0.863238</td>\n",
       "      <td>0.833490</td>\n",
       "      <td>0.501711</td>\n",
       "      <td>0.748864</td>\n",
       "      <td>0.835741</td>\n",
       "      <td>0.850335</td>\n",
       "      <td>0.506388</td>\n",
       "      <td>0.787369</td>\n",
       "      <td>0.854412</td>\n",
       "      <td>0.821265</td>\n",
       "      <td>0.494142</td>\n",
       "      <td>0.735308</td>\n",
       "      <td>0.865700</td>\n",
       "      <td>0.828476</td>\n",
       "      <td>0.493642</td>\n",
       "      <td>0.754923</td>\n",
       "      <td>0.880036</td>\n",
       "      <td>0.839849</td>\n",
       "      <td>0.499795</td>\n",
       "      <td>0.724391</td>\n",
       "      <td>0.860711</td>\n",
       "      <td>0.829810</td>\n",
       "      <td>0.491773</td>\n",
       "      <td>0.745289</td>\n",
       "      <td>0.869008</td>\n",
       "      <td>0.831409</td>\n",
       "      <td>0.492656</td>\n",
       "      <td>0.766507</td>\n",
       "      <td>0.838898</td>\n",
       "      <td>0.842981</td>\n",
       "      <td>0.498294</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.543020</td>\n",
       "      <td>2.333912</td>\n",
       "      <td>2.445605</td>\n",
       "      <td>3.778629</td>\n",
       "      <td>2.569812</td>\n",
       "      <td>2.348830</td>\n",
       "      <td>2.753787</td>\n",
       "      <td>3.933434</td>\n",
       "      <td>2.604758</td>\n",
       "      <td>2.060467</td>\n",
       "      <td>2.773804</td>\n",
       "      <td>3.930845</td>\n",
       "      <td>2.551725</td>\n",
       "      <td>2.342384</td>\n",
       "      <td>2.741127</td>\n",
       "      <td>3.769022</td>\n",
       "      <td>2.582013</td>\n",
       "      <td>2.044478</td>\n",
       "      <td>2.742619</td>\n",
       "      <td>3.908307</td>\n",
       "      <td>2.612386</td>\n",
       "      <td>2.059880</td>\n",
       "      <td>2.752623</td>\n",
       "      <td>3.908156</td>\n",
       "      <td>2.565264</td>\n",
       "      <td>2.088634</td>\n",
       "      <td>2.455091</td>\n",
       "      <td>3.756429</td>\n",
       "      <td>2.598145</td>\n",
       "      <td>2.050772</td>\n",
       "      <td>2.747083</td>\n",
       "      <td>3.905865</td>\n",
       "      <td>2.631955</td>\n",
       "      <td>2.066056</td>\n",
       "      <td>2.759666</td>\n",
       "      <td>3.909603</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Aattr        Battr        Cattr        Dattr        Eattr  \\\n",
       "count  6430.000000  6430.000000  6430.000000  6430.000000  6430.000000   \n",
       "mean     -0.000846    -0.000748    -0.000603    -0.000272    -0.000863   \n",
       "std       0.999648     0.999943     0.999966     1.000202     0.999697   \n",
       "min      -2.234329    -2.473310    -2.780894    -2.624275    -2.223275   \n",
       "25%      -0.690878    -0.550421    -0.858503    -0.719279    -0.674739   \n",
       "50%      -0.102897     0.148811     0.102692    -0.084280    -0.084821   \n",
       "75%       0.779075     0.848043     0.823588     0.497802     0.800057   \n",
       "max       2.543020     2.333912     2.445605     3.778629     2.569812   \n",
       "\n",
       "             Fattr       A1attr       B2attr       C3attr       D4attr  \\\n",
       "count  6430.000000  6430.000000  6430.000000  6430.000000  6430.000000   \n",
       "mean     -0.000787    -0.000611    -0.000333    -0.000767    -0.000779   \n",
       "std       0.999955     0.999969     1.000220     0.999806     0.999907   \n",
       "min      -2.457498    -2.947095    -2.824420    -2.146330    -2.444776   \n",
       "25%      -0.534967    -0.846770    -0.712591    -0.661615    -0.520206   \n",
       "50%       0.076748     0.113379    -0.079042    -0.141965     0.092157   \n",
       "75%       0.863238     0.833490     0.501711     0.748864     0.835741   \n",
       "max       2.348830     2.753787     3.933434     2.604758     2.060467   \n",
       "\n",
       "            E5attr       F6attr       A7attr       B8attr       C9attr  \\\n",
       "count  6430.000000  6430.000000  6430.000000  6430.000000  6430.000000   \n",
       "mean     -0.000540    -0.000279    -0.000829    -0.000760    -0.000536   \n",
       "std       0.999958     1.000201     0.999639     0.999954     1.000095   \n",
       "min      -2.936494    -2.812701    -2.226740    -2.471642    -2.958463   \n",
       "25%      -0.832700    -0.758027    -0.682928    -0.546032    -0.858614   \n",
       "50%       0.068926    -0.073135    -0.094810     0.066663     0.101317   \n",
       "75%       0.850335     0.506388     0.787369     0.854412     0.821265   \n",
       "max       2.773804     3.930845     2.551725     2.342384     2.741127   \n",
       "\n",
       "           D10attr      E11attr      F12attr      A13attr      B14attr  \\\n",
       "count  6430.000000  6430.000000  6430.000000  6430.000000  6430.000000   \n",
       "mean     -0.000294    -0.000698    -0.000768    -0.000467    -0.000204   \n",
       "std       1.000235     0.999869     0.999969     1.000126     1.000260   \n",
       "min      -2.833559    -2.145554    -2.452344    -2.939991    -2.815957   \n",
       "25%      -0.720733    -0.668189    -0.531371    -0.846398    -0.714624   \n",
       "50%      -0.086885    -0.077243     0.079847     0.050856    -0.084225   \n",
       "75%       0.494142     0.735308     0.865700     0.828476     0.493642   \n",
       "max       3.769022     2.582013     2.044478     2.742619     3.908307   \n",
       "\n",
       "           C15attr      D16attr      E17attr      F18attr      A19attr  \\\n",
       "count  6430.000000  6430.000000  6430.000000  6430.000000  6430.000000   \n",
       "mean     -0.000599    -0.000732    -0.000579    -0.000274    -0.000598   \n",
       "std       1.000001     0.999987     1.000072     1.000214     1.000039   \n",
       "min      -2.217016    -2.441006    -2.925927    -2.803693    -2.221005   \n",
       "25%      -0.656748    -0.518297    -0.833829    -0.758677    -0.674672   \n",
       "50%      -0.136658     0.049776     0.062784    -0.077004    -0.085593   \n",
       "75%       0.754923     0.880036     0.839849     0.499795     0.724391   \n",
       "max       2.612386     2.059880     2.752623     3.908156     2.565264   \n",
       "\n",
       "           B20attr      C21attr      D22attr      E23attr      F24attr  \\\n",
       "count  6430.000000  6430.000000  6430.000000  6430.000000  6430.000000   \n",
       "mean     -0.000710    -0.000430    -0.000178    -0.000626    -0.000717   \n",
       "std       1.000009     1.000191     1.000274     0.999900     1.000023   \n",
       "min      -2.472222    -2.962511    -2.825539    -2.219281    -2.457440   \n",
       "25%      -0.542629    -0.855666    -0.719309    -0.662882    -0.531602   \n",
       "50%       0.071332     0.047268    -0.087440    -0.069968     0.081165   \n",
       "75%       0.860711     0.829810     0.491773     0.745289     0.869008   \n",
       "max       2.088634     2.455091     3.756429     2.598145     2.050772   \n",
       "\n",
       "           A25attr      B26attr      C27attr      D28attr      E29attr  \\\n",
       "count  6430.000000  6430.000000  6430.000000  6430.000000  6430.000000   \n",
       "mean     -0.000525    -0.000212    -0.000596    -0.000666    -0.000469   \n",
       "std       1.000017     1.000276     0.999877     1.000010     1.000005   \n",
       "min      -2.940074    -2.815531    -2.218211    -2.448131    -2.930494   \n",
       "25%      -0.844805    -0.715095    -0.651234    -0.519740    -0.834119   \n",
       "50%       0.053167    -0.084964    -0.128909     0.050011     0.064327   \n",
       "75%       0.831409     0.492656     0.766507     0.838898     0.842981   \n",
       "max       2.747083     3.905865     2.631955     2.066056     2.759666   \n",
       "\n",
       "           F30attr        class  \n",
       "count  6430.000000  6430.000000  \n",
       "mean     -0.000126     2.435148  \n",
       "std       1.000286     1.876348  \n",
       "min      -2.808050     0.000000  \n",
       "25%      -0.761265     1.000000  \n",
       "50%      -0.079004     2.000000  \n",
       "75%       0.498294     4.000000  \n",
       "max       3.909603     5.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab4544e1-094d-4daa-a279-face530971f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "# Number of Classes\n",
    "n_classes = df['class'].nunique()\n",
    "\n",
    "print('Number of classes: {}'.format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77a3f1cd-7d05-4a44-bea5-d80863eb9e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Classes\n",
    "classes = np.sort(df['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b326ff20-2af5-43c2-bba0-52ec1dfd58a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78612c45-37c0-4e80-b1ad-9a95999c3f2c",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa9ddbd6-d237-40a3-bc10-33ce93a8fb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6430 entries, 0 to 6429\n",
      "Data columns (total 37 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Aattr    6430 non-null   float32\n",
      " 1   Battr    6430 non-null   float32\n",
      " 2   Cattr    6430 non-null   float32\n",
      " 3   Dattr    6430 non-null   float32\n",
      " 4   Eattr    6430 non-null   float32\n",
      " 5   Fattr    6430 non-null   float32\n",
      " 6   A1attr   6430 non-null   float32\n",
      " 7   B2attr   6430 non-null   float32\n",
      " 8   C3attr   6430 non-null   float32\n",
      " 9   D4attr   6430 non-null   float32\n",
      " 10  E5attr   6430 non-null   float32\n",
      " 11  F6attr   6430 non-null   float32\n",
      " 12  A7attr   6430 non-null   float32\n",
      " 13  B8attr   6430 non-null   float32\n",
      " 14  C9attr   6430 non-null   float32\n",
      " 15  D10attr  6430 non-null   float32\n",
      " 16  E11attr  6430 non-null   float32\n",
      " 17  F12attr  6430 non-null   float32\n",
      " 18  A13attr  6430 non-null   float32\n",
      " 19  B14attr  6430 non-null   float32\n",
      " 20  C15attr  6430 non-null   float32\n",
      " 21  D16attr  6430 non-null   float32\n",
      " 22  E17attr  6430 non-null   float32\n",
      " 23  F18attr  6430 non-null   float32\n",
      " 24  A19attr  6430 non-null   float32\n",
      " 25  B20attr  6430 non-null   float32\n",
      " 26  C21attr  6430 non-null   float32\n",
      " 27  D22attr  6430 non-null   float32\n",
      " 28  E23attr  6430 non-null   float32\n",
      " 29  F24attr  6430 non-null   float32\n",
      " 30  A25attr  6430 non-null   float32\n",
      " 31  B26attr  6430 non-null   float32\n",
      " 32  C27attr  6430 non-null   float32\n",
      " 33  D28attr  6430 non-null   float32\n",
      " 34  E29attr  6430 non-null   float32\n",
      " 35  F30attr  6430 non-null   float32\n",
      " 36  class    6430 non-null   int64  \n",
      "dtypes: float32(36), int64(1)\n",
      "memory usage: 954.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "698f6bc4-1610-46d3-af97-384f7d82d8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df memory: 0.9322090148925781 MB\n",
      "Proposed df memory: 0.8892841339111328 MB\n"
     ]
    }
   ],
   "source": [
    "print(f'Original df memory: {df.memory_usage(deep=True).sum()/1024/1024} MB')\n",
    "proposed_df = report_on_dataframe(df, unit=\"MB\")\n",
    "\n",
    "df = optimize_dtypes(df, proposed_df)\n",
    "print(f'Proposed df memory: {df.memory_usage(deep=True).sum()/1024/1024} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89a6f0fc-4e01-409a-841c-10b6a5ddedfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cal, df_test = train_test_split(df, test_size = 500, random_state = 42, shuffle = True)\n",
    "\n",
    "df_proper_train, df_cal = train_test_split(df_train_cal, test_size = 500, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83040363-8f89-414c-9ee5-83643fef2210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proper Training Set Size: 5430\n",
      "Calibration Set Size: 500\n",
      "Test Set Size: 500\n"
     ]
    }
   ],
   "source": [
    "print('Proper Training Set Size: {}'.format(len(df_proper_train)))\n",
    "\n",
    "print('Calibration Set Size: {}'.format(len(df_cal)))\n",
    "\n",
    "print('Test Set Size: {}'.format(len(df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01acc36d-b99b-4a35-a5c7-907cf6eea5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_cal.drop('class', axis=1)\n",
    "y_train = df_train_cal['class']\n",
    "\n",
    "X_proper_train = df_proper_train.drop('class', axis=1)\n",
    "y_proper_train = df_proper_train['class']\n",
    "\n",
    "X_cal = df_cal.drop('class', axis=1)\n",
    "y_cal = df_cal['class']\n",
    "\n",
    "X_test = df_test.drop('class', axis=1)\n",
    "y_test = df_test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41bc5e90-4c10-428f-987f-130c20e5a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "\n",
    "y_test_binary = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37ca2eeb-5975-4c43-9748-3205b5352f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       ...,\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7206d95b-7144-418b-8586-dc7064a935de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_loss_calc(y_true, prob):\n",
    "    return ((y_true - prob)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7671696a-ab9b-4d90-a6e3-443847dc42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame Record Model's Performance\n",
    "model_names = ['Naive Bayes', 'Logistic Regression', 'Random Forest Classifier',\n",
    "               'AdaBoost Classifier', 'CatBoost Classifier', 'SVC', 'LGBM Classifier', 'XGBoost Classifier']\n",
    "\n",
    "methods = ['uncalibrated',\t'Platt',\t'Isotonic',\t'Platt-CV',\t'Isotonic-CV',\t'IVAP',\t'CVAP']\n",
    "\n",
    "accuracy_df = pd.DataFrame(index=model_names, columns=methods)\n",
    "\n",
    "# Brier and the Log loss DataFrame Result Storage\n",
    "brier_loss_df = accuracy_df.copy()\n",
    "log_loss_df = accuracy_df.copy()\n",
    "\n",
    "# Record Execution Times\n",
    "time_df = pd.DataFrame(index=model_names, columns=['Execution Time (s)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e96f6b3-319b-4ead-933a-0104468367f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c671791a-e95e-48d6-a476-2252adc9b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(model, model_name):\n",
    "\n",
    "  start_time = time.time()  # Record start time\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Predict class score on the test set\n",
    "  p_pred = model.predict_proba(X_test)\n",
    "  # Predict on the test set\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  # Compute results of the Underlying Classifier\n",
    "  accuracy_df.loc[model_name, 'uncalibrated'] = accuracy_score(y_test, y_pred)\n",
    "  log_loss_df.loc[model_name, 'uncalibrated'] = log_loss(y_test, p_pred)\n",
    "  brier_loss_df.loc[model_name, 'uncalibrated'] = brier_loss_calc(y_test_binary, p_pred)\n",
    "\n",
    "  # Compute results for Platt calibrator\n",
    "  model.fit(X_proper_train, y_proper_train)\n",
    "  cal_sigm = CalibratedClassifierCV(model, method='sigmoid', cv='prefit')\n",
    "  cal_sigm.fit(X_cal, y_cal)\n",
    "\n",
    "  # Compute class and Probability of predicted class\n",
    "  p_pred = cal_sigm.predict_proba(X_test)\n",
    "  y_pred = cal_sigm.predict(X_test)\n",
    "\n",
    "  accuracy_df.loc[model_name, 'Platt'] = accuracy_score(y_test, y_pred)\n",
    "  log_loss_df.loc[model_name, 'Platt'] = log_loss(y_test, p_pred)\n",
    "  brier_loss_df.loc[model_name, 'Platt'] = brier_loss_calc(y_test_binary, p_pred)\n",
    "\n",
    "  # Compute results for Isotonic Regression Calibrator\n",
    "  cal_iso = CalibratedClassifierCV(model, method='isotonic', cv='prefit')\n",
    "  cal_iso.fit(X_cal, y_cal)\n",
    "  p_pred = cal_iso.predict_proba(X_test)\n",
    "  y_pred = cal_iso.predict(X_test)\n",
    "\n",
    "  accuracy_df.loc[model_name, 'Isotonic'] = accuracy_score(y_test, y_pred)\n",
    "  log_loss_df.loc[model_name, 'Isotonic'] = log_loss(y_test, p_pred)\n",
    "  brier_loss_df.loc[model_name, 'Isotonic'] = brier_loss_calc(y_test_binary, p_pred)\n",
    "\n",
    "  # compute results for Platt-CV Calibrator\n",
    "  cal_sigm_cv = CalibratedClassifierCV(model, method='sigmoid', cv=5)\n",
    "  cal_sigm_cv.fit(X_train, y_train)\n",
    "\n",
    "  # Compute Class and Probability of Predicted Class\n",
    "  p_pred = cal_sigm_cv.predict_proba(X_test)\n",
    "  y_pred = cal_sigm_cv.predict(X_test)\n",
    "\n",
    "  accuracy_df.loc[model_name, 'Platt-CV'] = accuracy_score(y_test, y_pred)\n",
    "  log_loss_df.loc[model_name, 'Platt-CV'] = log_loss(y_test, p_pred)\n",
    "  brier_loss_df.loc[model_name, 'Platt-CV'] = brier_loss_calc(y_test_binary, p_pred)\n",
    "\n",
    "  # Compute results for Isotonic-CV Calibrator\n",
    "  cal_iso_cv = CalibratedClassifierCV(model, method='isotonic', cv=5)\n",
    "  cal_iso_cv.fit(X_train, y_train)\n",
    "  p_pred = cal_iso_cv.predict_proba(X_test)\n",
    "  y_pred = cal_iso_cv.predict(X_test)\n",
    "\n",
    "  accuracy_df.loc[model_name, 'Isotonic-CV'] = accuracy_score(y_test, y_pred)\n",
    "  log_loss_df.loc[model_name, 'Isotonic-CV'] = log_loss(y_test, p_pred)\n",
    "  brier_loss_df.loc[model_name, 'Isotonic-CV'] = brier_loss_calc(y_test_binary, p_pred)\n",
    "\n",
    "  # Compute results for IVAP Calibrator\n",
    "  va = VennAbersCalibrator(model, inductive=True, cal_size=500, random_state=RANDOM_STATE)\n",
    "  va.fit(np.asarray(X_train), np.asarray(y_train))\n",
    "\n",
    "  p_pred_va = va.predict_proba(np.array(X_test))\n",
    "  y_pred = np.argmax(va.predict(X_test), axis=1)\n",
    "\n",
    "  accuracy_df.loc[model_name, 'IVAP'] = accuracy_score(y_test, y_pred)\n",
    "  log_loss_df.loc[model_name, 'IVAP'] = log_loss(y_test, p_pred_va)\n",
    "  brier_loss_df.loc[model_name, 'IVAP'] = brier_loss_calc(y_test_binary, p_pred_va)\n",
    "\n",
    "  # Compute results for CVAP Calibrator\n",
    "  va_cv = VennAbersCalibrator(model, inductive=False, n_splits=5)\n",
    "  va_cv.fit(np.asarray(X_train), np.asarray(y_train))\n",
    "  p_pred_cv = va_cv.predict_proba(np.asarray(X_test))\n",
    "  y_pred =  np.argmax(va_cv.predict(X_test), axis=1)\n",
    "\n",
    "  accuracy_df.loc[model_name, 'CVAP'] = accuracy_score(y_test, y_pred)\n",
    "  log_loss_df.loc[model_name, 'CVAP'] = log_loss(y_test, p_pred_cv)\n",
    "  brier_loss_df.loc[model_name, 'CVAP'] = brier_loss_calc(y_test_binary, p_pred_cv)\n",
    "\n",
    "  end_time = time.time()  # Record end time\n",
    "  execution_time = end_time - start_time  # Calculate execution time in seconds\n",
    "\n",
    "  # Record Execution Time in the Time DataFrame\n",
    "  time_df.loc[model_name, 'Execution Time (s)'] = execution_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02edb30-ba20-4602-8995-52badfe69302",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9526d349-3325-42f2-aeca-ef183a8d85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(n_jobs=-1),\n",
    "    RandomForestClassifier(n_jobs=-1),\n",
    "    AdaBoostClassifier(),\n",
    "    CatBoostClassifier(task_type=\"GPU\" if is_cuda_available else \"CPU\",\n",
    "                       thread_count=-1, verbose=0, random_state=RANDOM_STATE),\n",
    "    SVC(probability=True),\n",
    "    LGBMClassifier(device='gpu' if is_cuda_available else 'cpu',\n",
    "                   random_state=RANDOM_STATE, n_jobs=-1, verbose=-1),\n",
    "    XGBClassifier(tree_method='gpu_hist' if is_cuda_available else 'auto',\n",
    "                  n_jobs=-1, num_class=n_classes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d094f3ce-62fd-45eb-8c91-c025beb239ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: Naive Bayes\n",
      "processing: Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/CP/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/CP/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/CP/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/CP/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/CP/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/CP/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/CP/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/CP/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: Random Forest Classifier\n",
      "processing: AdaBoost Classifier\n",
      "processing: CatBoost Classifier\n",
      "processing: SVC\n",
      "processing: LGBM Classifier\n",
      "processing: XGBoost Classifier\n"
     ]
    }
   ],
   "source": [
    "for model, model_name in zip(models, model_names):\n",
    "    print(f'processing: {model_name}')\n",
    "    evaluate_model_performance(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c92ad9dd-217a-4afe-aec9-6fcde0b29684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncalibrated</th>\n",
       "      <th>Platt</th>\n",
       "      <th>Isotonic</th>\n",
       "      <th>Platt-CV</th>\n",
       "      <th>Isotonic-CV</th>\n",
       "      <th>IVAP</th>\n",
       "      <th>CVAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM Classifier</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         uncalibrated  Platt Isotonic Platt-CV Isotonic-CV  \\\n",
       "Naive Bayes                     0.804  0.806    0.826    0.806       0.822   \n",
       "Logistic Regression             0.858  0.802    0.836      0.8       0.814   \n",
       "Random Forest Classifier        0.906  0.902    0.908    0.906       0.918   \n",
       "AdaBoost Classifier             0.758  0.628    0.746    0.724        0.78   \n",
       "CatBoost Classifier              0.92  0.908    0.894    0.916       0.918   \n",
       "SVC                             0.896  0.894    0.886    0.894        0.89   \n",
       "LGBM Classifier                  0.93  0.922    0.918    0.924        0.93   \n",
       "XGBoost Classifier              0.916  0.918    0.908    0.924       0.922   \n",
       "\n",
       "                           IVAP   CVAP  \n",
       "Naive Bayes                0.11   0.11  \n",
       "Logistic Regression       0.086  0.086  \n",
       "Random Forest Classifier    0.2    0.2  \n",
       "AdaBoost Classifier        0.11   0.11  \n",
       "CatBoost Classifier        0.11   0.11  \n",
       "SVC                       0.086  0.086  \n",
       "LGBM Classifier             0.2    0.2  \n",
       "XGBoost Classifier          0.2    0.2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b48c8b8-3844-4faa-818d-7db5f01d513b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncalibrated</th>\n",
       "      <th>Platt</th>\n",
       "      <th>Isotonic</th>\n",
       "      <th>Platt-CV</th>\n",
       "      <th>Isotonic-CV</th>\n",
       "      <th>IVAP</th>\n",
       "      <th>CVAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>3.613003</td>\n",
       "      <td>0.748671</td>\n",
       "      <td>0.771357</td>\n",
       "      <td>0.733909</td>\n",
       "      <td>0.54407</td>\n",
       "      <td>0.47586</td>\n",
       "      <td>0.472197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.330625</td>\n",
       "      <td>0.573444</td>\n",
       "      <td>0.676732</td>\n",
       "      <td>0.562123</td>\n",
       "      <td>0.486503</td>\n",
       "      <td>0.358059</td>\n",
       "      <td>0.353035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.261116</td>\n",
       "      <td>0.29372</td>\n",
       "      <td>0.510354</td>\n",
       "      <td>0.238923</td>\n",
       "      <td>0.217336</td>\n",
       "      <td>0.276607</td>\n",
       "      <td>0.282966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>1.149778</td>\n",
       "      <td>1.016316</td>\n",
       "      <td>1.610103</td>\n",
       "      <td>0.947233</td>\n",
       "      <td>0.7691</td>\n",
       "      <td>0.334828</td>\n",
       "      <td>0.331052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier</th>\n",
       "      <td>0.212955</td>\n",
       "      <td>0.314463</td>\n",
       "      <td>0.562956</td>\n",
       "      <td>0.263331</td>\n",
       "      <td>0.208423</td>\n",
       "      <td>0.267255</td>\n",
       "      <td>0.276707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.267523</td>\n",
       "      <td>0.352296</td>\n",
       "      <td>0.581797</td>\n",
       "      <td>0.31586</td>\n",
       "      <td>0.289213</td>\n",
       "      <td>0.301163</td>\n",
       "      <td>0.309649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM Classifier</th>\n",
       "      <td>0.23341</td>\n",
       "      <td>0.317691</td>\n",
       "      <td>0.429046</td>\n",
       "      <td>0.276056</td>\n",
       "      <td>0.198108</td>\n",
       "      <td>0.276244</td>\n",
       "      <td>0.273355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>0.257798</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>0.439266</td>\n",
       "      <td>0.276339</td>\n",
       "      <td>0.207936</td>\n",
       "      <td>0.275537</td>\n",
       "      <td>0.264474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         uncalibrated     Platt  Isotonic  Platt-CV  \\\n",
       "Naive Bayes                  3.613003  0.748671  0.771357  0.733909   \n",
       "Logistic Regression          0.330625  0.573444  0.676732  0.562123   \n",
       "Random Forest Classifier     0.261116   0.29372  0.510354  0.238923   \n",
       "AdaBoost Classifier          1.149778  1.016316  1.610103  0.947233   \n",
       "CatBoost Classifier          0.212955  0.314463  0.562956  0.263331   \n",
       "SVC                          0.267523  0.352296  0.581797   0.31586   \n",
       "LGBM Classifier               0.23341  0.317691  0.429046  0.276056   \n",
       "XGBoost Classifier           0.257798  0.331987  0.439266  0.276339   \n",
       "\n",
       "                         Isotonic-CV      IVAP      CVAP  \n",
       "Naive Bayes                  0.54407   0.47586  0.472197  \n",
       "Logistic Regression         0.486503  0.358059  0.353035  \n",
       "Random Forest Classifier    0.217336  0.276607  0.282966  \n",
       "AdaBoost Classifier           0.7691  0.334828  0.331052  \n",
       "CatBoost Classifier         0.208423  0.267255  0.276707  \n",
       "SVC                         0.289213  0.301163  0.309649  \n",
       "LGBM Classifier             0.198108  0.276244  0.273355  \n",
       "XGBoost Classifier          0.207936  0.275537  0.264474  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07f06b72-adcd-4336-bd40-46c0ecb5b6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncalibrated</th>\n",
       "      <th>Platt</th>\n",
       "      <th>Isotonic</th>\n",
       "      <th>Platt-CV</th>\n",
       "      <th>Isotonic-CV</th>\n",
       "      <th>IVAP</th>\n",
       "      <th>CVAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.062693</td>\n",
       "      <td>0.053826</td>\n",
       "      <td>0.046361</td>\n",
       "      <td>0.05356</td>\n",
       "      <td>0.043806</td>\n",
       "      <td>0.041693</td>\n",
       "      <td>0.041507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.031796</td>\n",
       "      <td>0.048106</td>\n",
       "      <td>0.043621</td>\n",
       "      <td>0.048054</td>\n",
       "      <td>0.044474</td>\n",
       "      <td>0.031765</td>\n",
       "      <td>0.030754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.023308</td>\n",
       "      <td>0.023465</td>\n",
       "      <td>0.023629</td>\n",
       "      <td>0.020798</td>\n",
       "      <td>0.020739</td>\n",
       "      <td>0.024356</td>\n",
       "      <td>0.023933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.095207</td>\n",
       "      <td>0.084701</td>\n",
       "      <td>0.073049</td>\n",
       "      <td>0.078731</td>\n",
       "      <td>0.065862</td>\n",
       "      <td>0.029676</td>\n",
       "      <td>0.02849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier</th>\n",
       "      <td>0.02027</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.023066</td>\n",
       "      <td>0.021605</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.022994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.025369</td>\n",
       "      <td>0.031599</td>\n",
       "      <td>0.029721</td>\n",
       "      <td>0.028589</td>\n",
       "      <td>0.027173</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>0.025991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM Classifier</th>\n",
       "      <td>0.019972</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>0.021968</td>\n",
       "      <td>0.020342</td>\n",
       "      <td>0.018867</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>0.022086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>0.022229</td>\n",
       "      <td>0.024251</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.020895</td>\n",
       "      <td>0.019776</td>\n",
       "      <td>0.02347</td>\n",
       "      <td>0.02195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         uncalibrated     Platt  Isotonic  Platt-CV  \\\n",
       "Naive Bayes                  0.062693  0.053826  0.046361   0.05356   \n",
       "Logistic Regression          0.031796  0.048106  0.043621  0.048054   \n",
       "Random Forest Classifier     0.023308  0.023465  0.023629  0.020798   \n",
       "AdaBoost Classifier          0.095207  0.084701  0.073049  0.078731   \n",
       "CatBoost Classifier           0.02027  0.023712  0.023066  0.021605   \n",
       "SVC                          0.025369  0.031599  0.029721  0.028589   \n",
       "LGBM Classifier              0.019972  0.022485  0.021968  0.020342   \n",
       "XGBoost Classifier           0.022229  0.024251  0.023363  0.020895   \n",
       "\n",
       "                         Isotonic-CV      IVAP      CVAP  \n",
       "Naive Bayes                 0.043806  0.041693  0.041507  \n",
       "Logistic Regression         0.044474  0.031765  0.030754  \n",
       "Random Forest Classifier    0.020739  0.024356  0.023933  \n",
       "AdaBoost Classifier         0.065862  0.029676   0.02849  \n",
       "CatBoost Classifier         0.020099  0.022546  0.022994  \n",
       "SVC                         0.027173  0.026027  0.025991  \n",
       "LGBM Classifier             0.018867  0.023301  0.022086  \n",
       "XGBoost Classifier          0.019776   0.02347   0.02195  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3a32de4-c282-4b7f-b57d-33ca0adbfbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Execution Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.494634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>12.276437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>11.54903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>13.176539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier</th>\n",
       "      <td>107.475952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>13.539231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM Classifier</th>\n",
       "      <td>17.97585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>7.773956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Execution Time (s)\n",
       "Naive Bayes                        0.494634\n",
       "Logistic Regression               12.276437\n",
       "Random Forest Classifier           11.54903\n",
       "AdaBoost Classifier               13.176539\n",
       "CatBoost Classifier              107.475952\n",
       "SVC                               13.539231\n",
       "LGBM Classifier                    17.97585\n",
       "XGBoost Classifier                 7.773956"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61c1fbf2-1e47-46d9-b61d-661617797306",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df.to_csv('accuracy.csv')\n",
    "log_loss_df.to_csv('log_loss.csv')\n",
    "brier_loss_df.to_csv('brier_loss.csv')\n",
    "time_df.to_csv('time_cpu.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf2b23-3437-452a-903a-54d828c34829",
   "metadata": {},
   "source": [
    "### Mean Brier & Log Loss Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "510fe5b6-69ab-4844-b4fa-47f18196c8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVAP            0.320429\n",
       "IVAP            0.320694\n",
       "Isotonic-CV     0.365086\n",
       "Platt-CV        0.451722\n",
       "Platt           0.493573\n",
       "Isotonic        0.697701\n",
       "uncalibrated    0.790776\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_df.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6eafb135-d615-4ad3-9991-354bfba00fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVAP            0.027213\n",
       "IVAP            0.027854\n",
       "Isotonic-CV       0.0326\n",
       "Isotonic        0.035597\n",
       "Platt-CV        0.036572\n",
       "uncalibrated    0.037605\n",
       "Platt           0.039018\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_loss_df.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a761f2dc-8fa9-4f1e-92db-c31cc172d968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Isotonic-CV     0.87425\n",
       "uncalibrated     0.8735\n",
       "Isotonic        0.86525\n",
       "Platt-CV        0.86175\n",
       "Platt            0.8475\n",
       "IVAP            0.13775\n",
       "CVAP            0.13775\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc9def-eb92-43e1-9486-6ea5ac99eb67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
